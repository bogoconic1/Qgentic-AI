2025-09-22 06:54:18,103 | INFO | Initialized logging system.
2025-09-22 06:54:18,103 | INFO | Logs will be written to: task/us-patent-phrase-to-phrase-matching/outputs/4/code_4_v4.txt
2025-09-22 06:54:18,105 | INFO | Config: {'seed': 42, 'model_name': 'microsoft/deberta-v3-large', 'max_length': 192, 'train_bs': 16, 'valid_bs': 32, 'epochs': 3, 'lr': 3e-05, 'weight_decay': 0.01, 'warmup_ratio': 0.1, 'num_workers': 4, 'fold_id': 0, 'n_splits': 5, 'gradient_accumulation_steps': 1, 'fp16': True, 'optimizer_eps': 1e-08, 'max_grad_norm': 1.0, 'dropout': 0.2, 'n_msd': 5, 'last_n_layers': 4, 'layer_decay': 0.95, 'gradient_checkpointing': False, 'lambda_reg': 0.5, 'lambda_exp': 0.25, 'lambda_cls': 0.25, 'blend_alpha': 0.5, 'train_file': 'task/us-patent-phrase-to-phrase-matching/train.csv', 'test_file': 'task/us-patent-phrase-to-phrase-matching/test.csv', 'titles_file': 'task/us-patent-phrase-to-phrase-matching/titles.csv', 'submission_file': 'task/us-patent-phrase-to-phrase-matching/outputs/4/submission_4.csv', 'log_interval': 100}
2025-09-22 06:54:18,105 | INFO | Seeding all RNGs with seed=42
2025-09-22 06:54:18,167 | INFO | Using device: cuda, CUDA device count: 1
2025-09-22 06:54:18,171 | INFO | CUDA device name: NVIDIA A100-SXM4-80GB
2025-09-22 06:54:18,171 | INFO | Loading CSV files.
2025-09-22 06:54:18,584 | INFO | Train shape: (32825, 5), columns: ['id', 'anchor', 'target', 'context', 'score']
2025-09-22 06:54:18,584 | INFO | Test shape: (3648, 5), columns: ['id', 'anchor', 'target', 'context', 'score']
2025-09-22 06:54:18,584 | INFO | Titles shape: (260476, 7), columns: ['code', 'title', 'section', 'class', 'subclass', 'group', 'main_group']
2025-09-22 06:54:18,585 | INFO | Column 'subgroup' not found in titles; creating empty column.
2025-09-22 06:54:18,586 | INFO | Merging CPC titles into train and test on context->code.
2025-09-22 06:54:18,728 | INFO | Post-merge train shape: (32825, 12), columns now: ['id', 'anchor', 'target', 'context', 'score', 'code', 'title', 'section', 'class', 'subclass', 'group', 'subgroup']
2025-09-22 06:54:18,728 | INFO | Post-merge test shape: (3648, 12), columns now: ['id', 'anchor', 'target', 'context', 'score', 'code', 'title', 'section', 'class', 'subclass', 'group', 'subgroup']
2025-09-22 06:54:18,728 | INFO | Checking for train-test leakage (overlap of (anchor, target, context)).
2025-09-22 06:54:18,771 | INFO | Number of overlapping (anchor, target, context) triplets: 0
2025-09-22 06:54:18,771 | INFO | Computing test context distribution (top 10).
2025-09-22 06:54:18,772 | INFO | Test context H01: count=230, pct=6.30%
2025-09-22 06:54:18,772 | INFO | Test context H04: count=215, pct=5.89%
2025-09-22 06:54:18,772 | INFO | Test context G01: count=179, pct=4.91%
2025-09-22 06:54:18,772 | INFO | Test context A61: count=165, pct=4.52%
2025-09-22 06:54:18,772 | INFO | Test context F16: count=121, pct=3.32%
2025-09-22 06:54:18,772 | INFO | Test context C07: count=115, pct=3.15%
2025-09-22 06:54:18,773 | INFO | Test context G06: count=99, pct=2.71%
2025-09-22 06:54:18,773 | INFO | Test context B60: count=94, pct=2.58%
2025-09-22 06:54:18,773 | INFO | Test context G02: count=89, pct=2.44%
2025-09-22 06:54:18,773 | INFO | Test context H03: count=83, pct=2.28%
2025-09-22 06:54:18,773 | INFO | Score distribution per context for H04, G01, A61.
2025-09-22 06:54:18,775 | INFO | Context H04: total=1962
2025-09-22 06:54:18,776 | INFO |   score=0.0: count=478
2025-09-22 06:54:18,776 | INFO |   score=0.25: count=617
2025-09-22 06:54:18,776 | INFO |   score=0.5: count=562
2025-09-22 06:54:18,776 | INFO |   score=0.75: count=251
2025-09-22 06:54:18,776 | INFO |   score=1.0: count=54
2025-09-22 06:54:18,778 | INFO | Context G01: total=1633
2025-09-22 06:54:18,778 | INFO |   score=0.0: count=355
2025-09-22 06:54:18,778 | INFO |   score=0.25: count=399
2025-09-22 06:54:18,778 | INFO |   score=0.5: count=655
2025-09-22 06:54:18,778 | INFO |   score=0.75: count=183
2025-09-22 06:54:18,778 | INFO |   score=1.0: count=41
2025-09-22 06:54:18,781 | INFO | Context A61: total=1312
2025-09-22 06:54:18,781 | INFO |   score=0.0: count=298
2025-09-22 06:54:18,782 | INFO |   score=0.25: count=376
2025-09-22 06:54:18,782 | INFO |   score=0.5: count=512
2025-09-22 06:54:18,782 | INFO |   score=0.75: count=102
2025-09-22 06:54:18,782 | INFO |   score=1.0: count=24
2025-09-22 06:54:18,784 | INFO | Maximum target character length in test.csv: 47
2025-09-22 06:54:18,784 | INFO | Checking mapping coverage of contexts to titles codes.
2025-09-22 06:54:18,820 | INFO | All train contexts covered by titles: True
2025-09-22 06:54:18,821 | INFO | All test contexts covered by titles: True
2025-09-22 06:54:18,821 | INFO | Building sentence pairs with CPC context prepended.
2025-09-22 06:54:20,344 | INFO | Sample train pairs:
2025-09-22 06:54:20,344 | INFO | FIRST: context: code: B60 | title: VEHICLES IN GENERAL | section: B | class: 60.0 | subclass:  [CTX] anchor: obstacle course
2025-09-22 06:54:20,344 | INFO | SECOND: target: obstacle position trajectory
2025-09-22 06:54:20,344 | INFO | FIRST: context: code: G06 | title: COMPUTING; CALCULATING; COUNTING | section: G | class: 6.0 | subclass:  [CTX] anchor: hardware blocks
2025-09-22 06:54:20,345 | INFO | SECOND: target: housing
2025-09-22 06:54:20,345 | INFO | FIRST: context: code: H04 | title: ELECTRIC COMMUNICATION TECHNIQUE | section: H | class: 4.0 | subclass:  [CTX] anchor: collator
2025-09-22 06:54:20,345 | INFO | SECOND: target: collation apparatus
2025-09-22 06:54:20,345 | INFO | Preparing stratified split (single fold).
2025-09-22 06:54:20,352 | INFO | Fold 0 sizes -> train: 26260, valid: 6565
2025-09-22 06:54:20,363 | INFO | Loading tokenizer.
2025-09-22 06:54:21,266 | INFO | Creating datasets and dataloaders.
2025-09-22 06:54:21,269 | INFO | Train batches: 1642, Valid batches: 206, Test batches: 114
2025-09-22 06:54:21,269 | INFO | Building model with weighted-layer pooling, mean pooling, and multi-sample dropout.
2025-09-22 06:54:22,904 | INFO | Gradient checkpointing is disabled in this run for graph-safety with MSD and multi-loss.
2025-09-22 06:54:24,181 | INFO | Model loaded: microsoft/deberta-v3-large
2025-09-22 06:54:24,182 | INFO | Total parameters: 434018314
2025-09-22 06:54:24,183 | INFO | Trainable parameters: 434018314
2025-09-22 06:54:24,183 | INFO | Creating optimizer parameter groups with layer-wise LR decay.
2025-09-22 06:54:24,184 | INFO | Group 0: params=1, lr=0.00000832, wd=0.01
2025-09-22 06:54:24,184 | INFO | Group 1: params=2, lr=0.00000832, wd=0.0
2025-09-22 06:54:24,184 | INFO | Group 2: params=6, lr=0.00000876, wd=0.01
2025-09-22 06:54:24,184 | INFO | Group 3: params=10, lr=0.00000876, wd=0.0
2025-09-22 06:54:24,184 | INFO | Group 4: params=6, lr=0.00000922, wd=0.01
2025-09-22 06:54:24,184 | INFO | Group 5: params=10, lr=0.00000922, wd=0.0
2025-09-22 06:54:24,184 | INFO | Group 6: params=6, lr=0.00000971, wd=0.01
2025-09-22 06:54:24,184 | INFO | Group 7: params=10, lr=0.00000971, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 8: params=6, lr=0.00001022, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 9: params=10, lr=0.00001022, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 10: params=6, lr=0.00001075, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 11: params=10, lr=0.00001075, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 12: params=6, lr=0.00001132, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 13: params=10, lr=0.00001132, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 14: params=6, lr=0.00001192, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 15: params=10, lr=0.00001192, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 16: params=6, lr=0.00001254, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 17: params=10, lr=0.00001254, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 18: params=6, lr=0.00001320, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 19: params=10, lr=0.00001320, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 20: params=6, lr=0.00001390, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 21: params=10, lr=0.00001390, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 22: params=6, lr=0.00001463, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 23: params=10, lr=0.00001463, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 24: params=6, lr=0.00001540, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 25: params=10, lr=0.00001540, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 26: params=6, lr=0.00001621, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 27: params=10, lr=0.00001621, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 28: params=6, lr=0.00001706, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 29: params=10, lr=0.00001706, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 30: params=6, lr=0.00001796, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 31: params=10, lr=0.00001796, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 32: params=6, lr=0.00001891, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 33: params=10, lr=0.00001891, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 34: params=6, lr=0.00001990, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 35: params=10, lr=0.00001990, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 36: params=6, lr=0.00002095, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 37: params=10, lr=0.00002095, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 38: params=6, lr=0.00002205, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 39: params=10, lr=0.00002205, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 40: params=6, lr=0.00002321, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 41: params=10, lr=0.00002321, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 42: params=6, lr=0.00002444, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 43: params=10, lr=0.00002444, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 44: params=6, lr=0.00002572, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 45: params=10, lr=0.00002572, wd=0.0
2025-09-22 06:54:24,185 | INFO | Group 46: params=6, lr=0.00002708, wd=0.01
2025-09-22 06:54:24,185 | INFO | Group 47: params=10, lr=0.00002708, wd=0.0
2025-09-22 06:54:24,186 | INFO | Group 48: params=6, lr=0.00002850, wd=0.01
2025-09-22 06:54:24,186 | INFO | Group 49: params=10, lr=0.00002850, wd=0.0
2025-09-22 06:54:24,186 | INFO | Group 50: params=4, lr=0.00003000, wd=0.01
2025-09-22 06:54:24,186 | INFO | Group 51: params=4, lr=0.00003000, wd=0.0
2025-09-22 06:54:24,187 | INFO | Training steps: 4926, Warmup steps: 492
2025-09-22 06:54:24,188 | INFO | Starting training with CUDA fp16, multi-task objectives, cosine schedule, and LLRD.
2025-09-22 06:54:44,557 | INFO | Epoch 1/3 | Step 100/1642 | Loss: 0.396651 (reg=0.092471, exp=0.062969, cls=1.338692) | LR: 0.00000169
2025-09-22 06:55:03,335 | INFO | Epoch 1/3 | Step 200/1642 | Loss: 0.394634 (reg=0.063950, exp=0.061897, cls=1.388738) | LR: 0.00000338
2025-09-22 06:55:22,029 | INFO | Epoch 1/3 | Step 300/1642 | Loss: 0.336437 (reg=0.152755, exp=0.029344, cls=1.010894) | LR: 0.00000507
2025-09-22 06:55:40,662 | INFO | Epoch 1/3 | Step 400/1642 | Loss: 0.159491 (reg=0.021881, exp=0.011184, cls=0.583017) | LR: 0.00000677
2025-09-22 06:55:59,369 | INFO | Epoch 1/3 | Step 500/1642 | Loss: 0.231681 (reg=0.012017, exp=0.024722, cls=0.877969) | LR: 0.00000832
2025-09-22 06:56:18,190 | INFO | Epoch 1/3 | Step 600/1642 | Loss: 0.188935 (reg=0.042878, exp=0.013888, cls=0.656093) | LR: 0.00000831
2025-09-22 06:56:37,024 | INFO | Epoch 1/3 | Step 700/1642 | Loss: 0.205082 (reg=0.031721, exp=0.017385, cls=0.739502) | LR: 0.00000828
2025-09-22 06:56:55,767 | INFO | Epoch 1/3 | Step 800/1642 | Loss: 0.271143 (reg=0.034699, exp=0.029647, cls=0.985527) | LR: 0.00000822
2025-09-22 06:57:14,635 | INFO | Epoch 1/3 | Step 900/1642 | Loss: 0.152503 (reg=0.021575, exp=0.011807, cls=0.555055) | LR: 0.00000815
2025-09-22 06:57:33,886 | INFO | Epoch 1/3 | Step 1000/1642 | Loss: 0.095726 (reg=0.013943, exp=0.007646, cls=0.347373) | LR: 0.00000806
2025-09-22 06:57:52,561 | INFO | Epoch 1/3 | Step 1100/1642 | Loss: 0.319156 (reg=0.060550, exp=0.056470, cls=1.099056) | LR: 0.00000794
2025-09-22 06:58:11,433 | INFO | Epoch 1/3 | Step 1200/1642 | Loss: 0.186296 (reg=0.023038, exp=0.018203, cls=0.680908) | LR: 0.00000781
2025-09-22 06:58:30,185 | INFO | Epoch 1/3 | Step 1300/1642 | Loss: 0.239495 (reg=0.022425, exp=0.025109, cls=0.888019) | LR: 0.00000766
2025-09-22 06:58:48,818 | INFO | Epoch 1/3 | Step 1400/1642 | Loss: 0.137345 (reg=0.018910, exp=0.010766, cls=0.500793) | LR: 0.00000749
2025-09-22 06:59:07,309 | INFO | Epoch 1/3 | Step 1500/1642 | Loss: 0.171030 (reg=0.013452, exp=0.009841, cls=0.647376) | LR: 0.00000730
2025-09-22 06:59:26,073 | INFO | Epoch 1/3 | Step 1600/1642 | Loss: 0.202918 (reg=0.038170, exp=0.036585, cls=0.698748) | LR: 0.00000710
2025-09-22 06:59:33,809 | INFO | Epoch 1 done. Avg train loss: 0.261107 (reg=0.039216, exp=0.031427, cls=0.934568) | Time: 309.62s
2025-09-22 06:59:47,975 | INFO | Validation epoch 1: MSE(reg)=0.026166, MSE(exp)=0.021285, MSE(blend)=0.023073 | Pearson(reg)=0.820569, Pearson(exp)=0.834427, Pearson(blend)=0.830264
2025-09-22 06:59:47,975 | INFO | New best validation Pearson (blend): 0.830264 at epoch 1
2025-09-22 07:00:06,769 | INFO | Epoch 2/3 | Step 100/1642 | Loss: 0.155448 (reg=0.020685, exp=0.014999, cls=0.565423) | LR: 0.00000679
2025-09-22 07:00:25,584 | INFO | Epoch 2/3 | Step 200/1642 | Loss: 0.189162 (reg=0.028176, exp=0.014918, cls=0.685381) | LR: 0.00000656
2025-09-22 07:00:44,223 | INFO | Epoch 2/3 | Step 300/1642 | Loss: 0.118205 (reg=0.014329, exp=0.009890, cls=0.434273) | LR: 0.00000631
2025-09-22 07:01:02,875 | INFO | Epoch 2/3 | Step 400/1642 | Loss: 0.118009 (reg=0.014402, exp=0.009895, cls=0.433336) | LR: 0.00000605
2025-09-22 07:01:22,100 | INFO | Epoch 2/3 | Step 500/1642 | Loss: 0.217784 (reg=0.049691, exp=0.033121, cls=0.738634) | LR: 0.00000579
2025-09-22 07:01:38,966 | INFO | Epoch 2/3 | Step 600/1642 | Loss: 0.146934 (reg=0.020691, exp=0.009602, cls=0.536752) | LR: 0.00000551
2025-09-22 07:01:54,503 | INFO | Epoch 2/3 | Step 700/1642 | Loss: 0.123088 (reg=0.014340, exp=0.013130, cls=0.450541) | LR: 0.00000523
2025-09-22 07:02:13,051 | INFO | Epoch 2/3 | Step 800/1642 | Loss: 0.115846 (reg=0.016297, exp=0.007335, cls=0.423457) | LR: 0.00000494
2025-09-22 07:02:31,821 | INFO | Epoch 2/3 | Step 900/1642 | Loss: 0.119629 (reg=0.011746, exp=0.006959, cls=0.448063) | LR: 0.00000465
2025-09-22 07:02:50,648 | INFO | Epoch 2/3 | Step 1000/1642 | Loss: 0.221990 (reg=0.025459, exp=0.025001, cls=0.812040) | LR: 0.00000436
2025-09-22 07:03:09,396 | INFO | Epoch 2/3 | Step 1100/1642 | Loss: 0.160381 (reg=0.010400, exp=0.007434, cls=0.613292) | LR: 0.00000406
2025-09-22 07:03:28,124 | INFO | Epoch 2/3 | Step 1200/1642 | Loss: 0.192082 (reg=0.018477, exp=0.015167, cls=0.716205) | LR: 0.00000377
2025-09-22 07:03:47,081 | INFO | Epoch 2/3 | Step 1300/1642 | Loss: 0.189650 (reg=0.018643, exp=0.018641, cls=0.702672) | LR: 0.00000348
2025-09-22 07:04:05,808 | INFO | Epoch 2/3 | Step 1400/1642 | Loss: 0.259501 (reg=0.059876, exp=0.057783, cls=0.860468) | LR: 0.00000319
2025-09-22 07:04:24,054 | INFO | Epoch 2/3 | Step 1500/1642 | Loss: 0.100998 (reg=0.012134, exp=0.007552, cls=0.372174) | LR: 0.00000290
2025-09-22 07:04:42,768 | INFO | Epoch 2/3 | Step 1600/1642 | Loss: 0.127379 (reg=0.014731, exp=0.007529, cls=0.472525) | LR: 0.00000263
2025-09-22 07:04:50,652 | INFO | Epoch 2 done. Avg train loss: 0.156048 (reg=0.018490, exp=0.014075, cls=0.573138) | Time: 302.68s
2025-09-22 07:05:04,615 | INFO | Validation epoch 2: MSE(reg)=0.021692, MSE(exp)=0.017737, MSE(blend)=0.019074 | Pearson(reg)=0.859067, Pearson(exp)=0.861521, Pearson(blend)=0.861571
2025-09-22 07:05:04,616 | INFO | New best validation Pearson (blend): 0.861571 at epoch 2
2025-09-22 07:05:23,699 | INFO | Epoch 3/3 | Step 100/1642 | Loss: 0.130867 (reg=0.014857, exp=0.008796, cls=0.484956) | LR: 0.00000225
2025-09-22 07:05:42,456 | INFO | Epoch 3/3 | Step 200/1642 | Loss: 0.133356 (reg=0.011318, exp=0.010375, cls=0.500412) | LR: 0.00000199
2025-09-22 07:06:01,195 | INFO | Epoch 3/3 | Step 300/1642 | Loss: 0.125214 (reg=0.013086, exp=0.010032, cls=0.464652) | LR: 0.00000174
2025-09-22 07:06:20,183 | INFO | Epoch 3/3 | Step 400/1642 | Loss: 0.124657 (reg=0.015031, exp=0.007001, cls=0.461565) | LR: 0.00000151
2025-09-22 07:06:38,292 | INFO | Epoch 3/3 | Step 500/1642 | Loss: 0.076208 (reg=0.004785, exp=0.004999, cls=0.290261) | LR: 0.00000129
2025-09-22 07:06:57,170 | INFO | Epoch 3/3 | Step 600/1642 | Loss: 0.034150 (reg=0.003195, exp=0.001085, cls=0.129122) | LR: 0.00000108
2025-09-22 07:07:15,994 | INFO | Epoch 3/3 | Step 700/1642 | Loss: 0.070936 (reg=0.009448, exp=0.009400, cls=0.255450) | LR: 0.00000089
2025-09-22 07:07:34,557 | INFO | Epoch 3/3 | Step 800/1642 | Loss: 0.250141 (reg=0.026830, exp=0.023346, cls=0.923558) | LR: 0.00000072
2025-09-22 07:07:53,157 | INFO | Epoch 3/3 | Step 900/1642 | Loss: 0.182427 (reg=0.011258, exp=0.011358, cls=0.695835) | LR: 0.00000056
2025-09-22 07:08:11,925 | INFO | Epoch 3/3 | Step 1000/1642 | Loss: 0.054121 (reg=0.008197, exp=0.003802, cls=0.196287) | LR: 0.00000042
2025-09-22 07:08:30,520 | INFO | Epoch 3/3 | Step 1100/1642 | Loss: 0.168169 (reg=0.012048, exp=0.010756, cls=0.637823) | LR: 0.00000030
2025-09-22 07:08:49,202 | INFO | Epoch 3/3 | Step 1200/1642 | Loss: 0.074104 (reg=0.006246, exp=0.005148, cls=0.278775) | LR: 0.00000020
2025-09-22 07:09:06,323 | INFO | Epoch 3/3 | Step 1300/1642 | Loss: 0.100618 (reg=0.008869, exp=0.008409, cls=0.376325) | LR: 0.00000012
2025-09-22 07:09:18,557 | INFO | Epoch 3/3 | Step 1400/1642 | Loss: 0.064362 (reg=0.008350, exp=0.003885, cls=0.236866) | LR: 0.00000006
2025-09-22 07:09:30,619 | INFO | Epoch 3/3 | Step 1500/1642 | Loss: 0.120337 (reg=0.009318, exp=0.010086, cls=0.452627) | LR: 0.00000002
2025-09-22 07:09:42,757 | INFO | Epoch 3/3 | Step 1600/1642 | Loss: 0.146928 (reg=0.018460, exp=0.011144, cls=0.539648) | LR: 0.00000000
2025-09-22 07:09:47,858 | INFO | Epoch 3 done. Avg train loss: 0.097542 (reg=0.010766, exp=0.007639, cls=0.360996) | Time: 283.24s
2025-09-22 07:09:55,595 | INFO | Validation epoch 3: MSE(reg)=0.018221, MSE(exp)=0.017551, MSE(blend)=0.017688 | Pearson(reg)=0.861453, Pearson(exp)=0.862478, Pearson(blend)=0.863153
2025-09-22 07:09:55,595 | INFO | New best validation Pearson (blend): 0.863153 at epoch 3
2025-09-22 07:09:55,595 | INFO | Final best validation Pearson correlation (blend): 0.863153 (epoch 3)
2025-09-22 07:09:55,595 | INFO | Validation history:
2025-09-22 07:09:55,595 | INFO |   Epoch 1: train_loss=0.261107, MSE(reg)=0.026166, MSE(exp)=0.021285, MSE(blend)=0.023073, Pearson(reg)=0.820569, Pearson(exp)=0.834427, Pearson(blend)=0.830264
2025-09-22 07:09:55,595 | INFO |   Epoch 2: train_loss=0.156048, MSE(reg)=0.021692, MSE(exp)=0.017737, MSE(blend)=0.019074, Pearson(reg)=0.859067, Pearson(exp)=0.861521, Pearson(blend)=0.861571
2025-09-22 07:09:55,595 | INFO |   Epoch 3: train_loss=0.097542, MSE(reg)=0.018221, MSE(exp)=0.017551, MSE(blend)=0.017688, Pearson(reg)=0.861453, Pearson(exp)=0.862478, Pearson(blend)=0.863153
2025-09-22 07:09:55,595 | INFO | Running final validation inference for logging (blend).
2025-09-22 07:10:03,382 | INFO | Final Validation Results (blend) -> MSE: 0.017688, Pearson: 0.863153
2025-09-22 07:10:03,382 | INFO | Running inference on test set (original and swapped TTA).
2025-09-22 07:10:12,486 | INFO | Preparing submission file.
2025-09-22 07:10:12,497 | INFO | Submission saved to: task/us-patent-phrase-to-phrase-matching/outputs/4/submission_4.csv
2025-09-22 07:10:12,497 | INFO | Extra analytics and diagnostics.
2025-09-22 07:10:12,499 | INFO | Train score=0.0: count=6774, pct=20.64%
2025-09-22 07:10:12,499 | INFO | Train score=0.25: count=10306, pct=31.40%
2025-09-22 07:10:12,499 | INFO | Train score=0.5: count=11068, pct=33.72%
2025-09-22 07:10:12,499 | INFO | Train score=0.75: count=3634, pct=11.07%
2025-09-22 07:10:12,499 | INFO | Train score=1.0: count=1043, pct=3.18%
2025-09-22 07:10:12,499 | INFO | Token length diagnostics (first 100 train samples).
2025-09-22 07:10:12,518 | INFO | Token length stats -> mean=50.77, max=77, min=38
2025-09-22 07:10:12,518 | INFO | Pipeline completed successfully with CUDA fp16, large cross-encoder, MTL head, LLRD, cosine schedule, and TTA. Ready for submission.
