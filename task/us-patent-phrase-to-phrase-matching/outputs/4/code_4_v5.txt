2025-09-22 07:18:13,169 | INFO | Initialized logging system.
2025-09-22 07:18:13,169 | INFO | Logs will be written to: task/us-patent-phrase-to-phrase-matching/outputs/4/code_4_v5.txt
2025-09-22 07:18:13,170 | INFO | Config: {'seed': 42, 'model_name': 'microsoft/deberta-v3-large', 'max_length': 256, 'train_bs': 16, 'valid_bs': 32, 'epochs': 3, 'lr': 3e-05, 'weight_decay': 0.01, 'warmup_ratio': 0.1, 'num_workers': 4, 'n_splits': 5, 'fp16': True, 'optimizer_eps': 1e-08, 'max_grad_norm': 1.0, 'dropout': 0.2, 'n_msd': 5, 'last_n_layers': 4, 'layer_decay': 0.95, 'gradient_checkpointing': False, 'lambda_reg': 0.5, 'lambda_exp': 0.25, 'lambda_cls': 0.25, 'rdrop_coef': 0.3, 'lambda_np': 0.05, 'blend_alpha': 0.5, 'adv_epsilon': 0.01, 'adv_weight': 0.5, 'adv_start_ratio': 0.1, 'ema_decay': 0.999, 'train_file': 'task/us-patent-phrase-to-phrase-matching/train.csv', 'test_file': 'task/us-patent-phrase-to-phrase-matching/test.csv', 'titles_file': 'task/us-patent-phrase-to-phrase-matching/titles.csv', 'submission_file': 'task/us-patent-phrase-to-phrase-matching/outputs/4/submission_5.csv', 'log_interval': 100}
2025-09-22 07:18:13,170 | INFO | Seeding all RNGs with seed=42
2025-09-22 07:18:13,403 | INFO | Using device: cuda, CUDA device count: 1
2025-09-22 07:18:13,408 | INFO | CUDA device name: NVIDIA A100-SXM4-80GB
2025-09-22 07:18:13,408 | INFO | Loading CSV files.
2025-09-22 07:18:13,754 | INFO | Train shape: (32825, 5), columns: ['id', 'anchor', 'target', 'context', 'score']
2025-09-22 07:18:13,754 | INFO | Test shape: (3648, 5), columns: ['id', 'anchor', 'target', 'context', 'score']
2025-09-22 07:18:13,754 | INFO | Titles shape: (260476, 7), columns: ['code', 'title', 'section', 'class', 'subclass', 'group', 'main_group']
2025-09-22 07:18:13,754 | INFO | Column 'subgroup' not found in titles; creating empty column.
2025-09-22 07:18:13,756 | INFO | Merging CPC titles into train and test on context->code.
2025-09-22 07:18:13,859 | INFO | Post-merge train shape: (32825, 12), columns now: ['id', 'anchor', 'target', 'context', 'score', 'code', 'title', 'section', 'class', 'subclass', 'group', 'subgroup']
2025-09-22 07:18:13,859 | INFO | Post-merge test shape: (3648, 12), columns now: ['id', 'anchor', 'target', 'context', 'score', 'code', 'title', 'section', 'class', 'subclass', 'group', 'subgroup']
2025-09-22 07:18:13,859 | INFO | Checking for train-test leakage (overlap of (anchor, target, context)).
2025-09-22 07:18:13,900 | INFO | Number of overlapping (anchor, target, context) triplets: 0
2025-09-22 07:18:13,900 | INFO | Computing test context distribution (top 10).
2025-09-22 07:18:13,901 | INFO | Test context H01: count=230, pct=6.30%
2025-09-22 07:18:13,901 | INFO | Test context H04: count=215, pct=5.89%
2025-09-22 07:18:13,901 | INFO | Test context G01: count=179, pct=4.91%
2025-09-22 07:18:13,901 | INFO | Test context A61: count=165, pct=4.52%
2025-09-22 07:18:13,901 | INFO | Test context F16: count=121, pct=3.32%
2025-09-22 07:18:13,901 | INFO | Test context C07: count=115, pct=3.15%
2025-09-22 07:18:13,901 | INFO | Test context G06: count=99, pct=2.71%
2025-09-22 07:18:13,901 | INFO | Test context B60: count=94, pct=2.58%
2025-09-22 07:18:13,901 | INFO | Test context G02: count=89, pct=2.44%
2025-09-22 07:18:13,901 | INFO | Test context H03: count=83, pct=2.28%
2025-09-22 07:18:13,901 | INFO | Score distribution per context for H04, G01, A61.
2025-09-22 07:18:13,904 | INFO | Context H04: total=1962
2025-09-22 07:18:13,904 | INFO |   score=0.0: count=478
2025-09-22 07:18:13,904 | INFO |   score=0.25: count=617
2025-09-22 07:18:13,904 | INFO |   score=0.5: count=562
2025-09-22 07:18:13,904 | INFO |   score=0.75: count=251
2025-09-22 07:18:13,904 | INFO |   score=1.0: count=54
2025-09-22 07:18:13,906 | INFO | Context G01: total=1633
2025-09-22 07:18:13,906 | INFO |   score=0.0: count=355
2025-09-22 07:18:13,906 | INFO |   score=0.25: count=399
2025-09-22 07:18:13,906 | INFO |   score=0.5: count=655
2025-09-22 07:18:13,906 | INFO |   score=0.75: count=183
2025-09-22 07:18:13,906 | INFO |   score=1.0: count=41
2025-09-22 07:18:13,908 | INFO | Context A61: total=1312
2025-09-22 07:18:13,909 | INFO |   score=0.0: count=298
2025-09-22 07:18:13,909 | INFO |   score=0.25: count=376
2025-09-22 07:18:13,909 | INFO |   score=0.5: count=512
2025-09-22 07:18:13,909 | INFO |   score=0.75: count=102
2025-09-22 07:18:13,909 | INFO |   score=1.0: count=24
2025-09-22 07:18:13,910 | INFO | Maximum target character length in test.csv: 47
2025-09-22 07:18:13,910 | INFO | Checking mapping coverage of contexts to titles codes.
2025-09-22 07:18:13,936 | INFO | All train contexts covered by titles: True
2025-09-22 07:18:13,936 | INFO | All test contexts covered by titles: True
2025-09-22 07:18:13,936 | INFO | Building sentence pairs with CPC context prepended.
2025-09-22 07:18:15,115 | INFO | Sample train pairs:
2025-09-22 07:18:15,116 | INFO | FIRST: context: code: B60 | title: VEHICLES IN GENERAL | section: B | class: 60.0 | subclass:  [CTX] anchor: obstacle course
2025-09-22 07:18:15,116 | INFO | SECOND: target: obstacle position trajectory
2025-09-22 07:18:15,116 | INFO | FIRST: context: code: G06 | title: COMPUTING; CALCULATING; COUNTING | section: G | class: 6.0 | subclass:  [CTX] anchor: hardware blocks
2025-09-22 07:18:15,116 | INFO | SECOND: target: housing
2025-09-22 07:18:15,116 | INFO | FIRST: context: code: H04 | title: ELECTRIC COMMUNICATION TECHNIQUE | section: H | class: 4.0 | subclass:  [CTX] anchor: collator
2025-09-22 07:18:15,116 | INFO | SECOND: target: collation apparatus
2025-09-22 07:18:15,116 | INFO | Preparing stratified K-Fold splits.
2025-09-22 07:18:15,126 | INFO | Total folds: 5
2025-09-22 07:18:15,126 | INFO | Loading tokenizer.
2025-09-22 07:18:16,146 | INFO | Creating test datasets and loaders.
2025-09-22 07:18:16,147 | INFO | Test batches (normal/swapped): 114/114
2025-09-22 07:18:16,147 | INFO | ===== Fold 1/5 =====
2025-09-22 07:18:16,164 | INFO | Fold 0 -> Train batches: 1642, Valid batches: 206
2025-09-22 07:18:18,241 | INFO | Creating optimizer parameter groups with layer-wise LR decay.
2025-09-22 07:18:18,243 | INFO | Group 0: params=1, lr=0.00000832, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 1: params=2, lr=0.00000832, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 2: params=6, lr=0.00000876, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 3: params=10, lr=0.00000876, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 4: params=6, lr=0.00000922, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 5: params=10, lr=0.00000922, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 6: params=6, lr=0.00000971, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 7: params=10, lr=0.00000971, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 8: params=6, lr=0.00001022, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 9: params=10, lr=0.00001022, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 10: params=6, lr=0.00001075, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 11: params=10, lr=0.00001075, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 12: params=6, lr=0.00001132, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 13: params=10, lr=0.00001132, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 14: params=6, lr=0.00001192, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 15: params=10, lr=0.00001192, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 16: params=6, lr=0.00001254, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 17: params=10, lr=0.00001254, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 18: params=6, lr=0.00001320, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 19: params=10, lr=0.00001320, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 20: params=6, lr=0.00001390, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 21: params=10, lr=0.00001390, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 22: params=6, lr=0.00001463, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 23: params=10, lr=0.00001463, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 24: params=6, lr=0.00001540, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 25: params=10, lr=0.00001540, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 26: params=6, lr=0.00001621, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 27: params=10, lr=0.00001621, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 28: params=6, lr=0.00001706, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 29: params=10, lr=0.00001706, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 30: params=6, lr=0.00001796, wd=0.01
2025-09-22 07:18:18,243 | INFO | Group 31: params=10, lr=0.00001796, wd=0.0
2025-09-22 07:18:18,243 | INFO | Group 32: params=6, lr=0.00001891, wd=0.01
2025-09-22 07:18:18,244 | INFO | Group 33: params=10, lr=0.00001891, wd=0.0
2025-09-22 07:18:18,244 | INFO | Group 34: params=6, lr=0.00001990, wd=0.01
2025-09-22 07:18:18,244 | INFO | Group 35: params=10, lr=0.00001990, wd=0.0
2025-09-22 07:18:18,244 | INFO | Group 36: params=6, lr=0.00002095, wd=0.01
2025-09-22 07:18:18,244 | INFO | Group 37: params=10, lr=0.00002095, wd=0.0
2025-09-22 07:18:18,244 | INFO | Group 38: params=6, lr=0.00002205, wd=0.01
2025-09-22 07:18:18,244 | INFO | Group 39: params=10, lr=0.00002205, wd=0.0
2025-09-22 07:18:18,244 | INFO | Group 40: params=6, lr=0.00002321, wd=0.01
2025-09-22 07:18:18,244 | INFO | Group 41: params=10, lr=0.00002321, wd=0.0
2025-09-22 07:18:18,244 | INFO | Group 42: params=6, lr=0.00002444, wd=0.01
2025-09-22 07:18:18,244 | INFO | Group 43: params=10, lr=0.00002444, wd=0.0
2025-09-22 07:18:18,244 | INFO | Group 44: params=6, lr=0.00002572, wd=0.01
2025-09-22 07:18:18,244 | INFO | Group 45: params=10, lr=0.00002572, wd=0.0
2025-09-22 07:18:18,244 | INFO | Group 46: params=6, lr=0.00002708, wd=0.01
2025-09-22 07:18:18,244 | INFO | Group 47: params=10, lr=0.00002708, wd=0.0
2025-09-22 07:18:18,244 | INFO | Group 48: params=6, lr=0.00002850, wd=0.01
2025-09-22 07:18:18,244 | INFO | Group 49: params=10, lr=0.00002850, wd=0.0
2025-09-22 07:18:18,244 | INFO | Group 50: params=4, lr=0.00003000, wd=0.01
2025-09-22 07:18:18,244 | INFO | Group 51: params=4, lr=0.00003000, wd=0.0
2025-09-22 07:18:18,246 | INFO | Fold 0 -> Training steps: 4926, Warmup steps: 492, Adv start step: 492
2025-09-22 07:18:18,246 | INFO | Registering EMA shadow parameters.
2025-09-22 07:18:18,263 | INFO | Starting epoch 1/3 for fold 0.
2025-09-22 07:18:51,797 | INFO | Fold 0 | Epoch 1/3 | Step 100/1642 | Loss: 0.439839 | LR: 0.00000169 | Adv:False
2025-09-22 07:19:25,107 | INFO | Fold 0 | Epoch 1/3 | Step 200/1642 | Loss: 0.441838 | LR: 0.00000338 | Adv:False
2025-09-22 07:19:58,308 | INFO | Fold 0 | Epoch 1/3 | Step 300/1642 | Loss: 0.325128 | LR: 0.00000507 | Adv:False
2025-09-22 07:20:31,976 | INFO | Fold 0 | Epoch 1/3 | Step 400/1642 | Loss: 0.201697 | LR: 0.00000677 | Adv:False
2025-09-22 07:21:05,869 | INFO | Fold 0 | Epoch 1/3 | Step 500/1642 | Loss: 0.221737 | LR: 0.00000832 | Adv:True
2025-09-22 07:21:53,301 | INFO | Fold 0 | Epoch 1/3 | Step 600/1642 | Loss: 0.170114 | LR: 0.00000831 | Adv:True
2025-09-22 07:22:41,395 | INFO | Fold 0 | Epoch 1/3 | Step 700/1642 | Loss: 0.220317 | LR: 0.00000828 | Adv:True
2025-09-22 07:23:28,731 | INFO | Fold 0 | Epoch 1/3 | Step 800/1642 | Loss: 0.268744 | LR: 0.00000822 | Adv:True
2025-09-22 07:24:16,510 | INFO | Fold 0 | Epoch 1/3 | Step 900/1642 | Loss: 0.169864 | LR: 0.00000815 | Adv:True
2025-09-22 07:25:04,394 | INFO | Fold 0 | Epoch 1/3 | Step 1000/1642 | Loss: 0.153151 | LR: 0.00000806 | Adv:True
2025-09-22 07:25:51,010 | INFO | Fold 0 | Epoch 1/3 | Step 1100/1642 | Loss: 0.338978 | LR: 0.00000794 | Adv:True
2025-09-22 07:26:35,098 | INFO | Fold 0 | Epoch 1/3 | Step 1200/1642 | Loss: 0.199389 | LR: 0.00000781 | Adv:True
2025-09-22 07:27:22,312 | INFO | Fold 0 | Epoch 1/3 | Step 1300/1642 | Loss: 0.267480 | LR: 0.00000766 | Adv:True
2025-09-22 07:28:09,341 | INFO | Fold 0 | Epoch 1/3 | Step 1400/1642 | Loss: 0.189730 | LR: 0.00000749 | Adv:True
2025-09-22 07:28:57,084 | INFO | Fold 0 | Epoch 1/3 | Step 1500/1642 | Loss: 0.174822 | LR: 0.00000730 | Adv:True
2025-09-22 07:29:44,609 | INFO | Fold 0 | Epoch 1/3 | Step 1600/1642 | Loss: 0.175375 | LR: 0.00000710 | Adv:True
2025-09-22 07:30:04,376 | INFO | Fold 0 | Epoch 1 done. Avg train loss: 0.275547 | Time: 706.11s
2025-09-22 07:30:04,376 | INFO | Applying EMA weights for evaluation.
2025-09-22 07:30:04,383 | INFO | Running validation inference (EMA-applied).
2025-09-22 07:30:18,273 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 07:30:18,282 | INFO | Fold 0 | Validation epoch 1: MSE(reg)=0.020439, MSE(exp)=0.022092, MSE(blend)=0.019696 | Pearson(reg)=0.839668, Pearson(exp)=0.840870, Pearson(blend)=0.841912
2025-09-22 07:30:18,282 | INFO | Fold 0 | New best validation Pearson (blend): 0.841912 at epoch 1
2025-09-22 07:30:18,282 | INFO | Applying EMA weights for evaluation.
2025-09-22 07:30:18,311 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 07:30:18,315 | INFO | Starting epoch 2/3 for fold 0.
2025-09-22 07:31:05,394 | INFO | Fold 0 | Epoch 2/3 | Step 100/1642 | Loss: 0.150223 | LR: 0.00000679 | Adv:True
2025-09-22 07:31:52,883 | INFO | Fold 0 | Epoch 2/3 | Step 200/1642 | Loss: 0.143053 | LR: 0.00000656 | Adv:True
2025-09-22 07:32:40,659 | INFO | Fold 0 | Epoch 2/3 | Step 300/1642 | Loss: 0.108094 | LR: 0.00000631 | Adv:True
2025-09-22 07:33:24,821 | INFO | Fold 0 | Epoch 2/3 | Step 400/1642 | Loss: 0.119404 | LR: 0.00000605 | Adv:True
2025-09-22 07:34:11,604 | INFO | Fold 0 | Epoch 2/3 | Step 500/1642 | Loss: 0.242450 | LR: 0.00000579 | Adv:True
2025-09-22 07:34:58,915 | INFO | Fold 0 | Epoch 2/3 | Step 600/1642 | Loss: 0.177452 | LR: 0.00000551 | Adv:True
2025-09-22 07:35:46,051 | INFO | Fold 0 | Epoch 2/3 | Step 700/1642 | Loss: 0.167833 | LR: 0.00000523 | Adv:True
2025-09-22 07:36:32,096 | INFO | Fold 0 | Epoch 2/3 | Step 800/1642 | Loss: 0.110259 | LR: 0.00000494 | Adv:True
2025-09-22 07:37:19,247 | INFO | Fold 0 | Epoch 2/3 | Step 900/1642 | Loss: 0.106733 | LR: 0.00000465 | Adv:True
2025-09-22 07:38:06,876 | INFO | Fold 0 | Epoch 2/3 | Step 1000/1642 | Loss: 0.139589 | LR: 0.00000436 | Adv:True
2025-09-22 07:38:53,576 | INFO | Fold 0 | Epoch 2/3 | Step 1100/1642 | Loss: 0.152467 | LR: 0.00000406 | Adv:True
2025-09-22 07:39:40,823 | INFO | Fold 0 | Epoch 2/3 | Step 1200/1642 | Loss: 0.152107 | LR: 0.00000377 | Adv:True
2025-09-22 07:40:28,760 | INFO | Fold 0 | Epoch 2/3 | Step 1300/1642 | Loss: 0.197578 | LR: 0.00000348 | Adv:True
2025-09-22 07:41:11,328 | INFO | Fold 0 | Epoch 2/3 | Step 1400/1642 | Loss: 0.142389 | LR: 0.00000319 | Adv:True
2025-09-22 07:41:58,330 | INFO | Fold 0 | Epoch 2/3 | Step 1500/1642 | Loss: 0.090151 | LR: 0.00000290 | Adv:True
2025-09-22 07:42:45,570 | INFO | Fold 0 | Epoch 2/3 | Step 1600/1642 | Loss: 0.133503 | LR: 0.00000263 | Adv:True
2025-09-22 07:43:05,240 | INFO | Fold 0 | Epoch 2 done. Avg train loss: 0.160686 | Time: 766.92s
2025-09-22 07:43:05,240 | INFO | Applying EMA weights for evaluation.
2025-09-22 07:43:05,246 | INFO | Running validation inference (EMA-applied).
2025-09-22 07:43:19,013 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 07:43:19,018 | INFO | Fold 0 | Validation epoch 2: MSE(reg)=0.018109, MSE(exp)=0.016499, MSE(blend)=0.016874 | Pearson(reg)=0.868039, Pearson(exp)=0.868784, Pearson(blend)=0.869266
2025-09-22 07:43:19,018 | INFO | Fold 0 | New best validation Pearson (blend): 0.869266 at epoch 2
2025-09-22 07:43:19,018 | INFO | Applying EMA weights for evaluation.
2025-09-22 07:43:19,044 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 07:43:19,048 | INFO | Starting epoch 3/3 for fold 0.
2025-09-22 07:44:06,401 | INFO | Fold 0 | Epoch 3/3 | Step 100/1642 | Loss: 0.104244 | LR: 0.00000225 | Adv:True
2025-09-22 07:44:53,817 | INFO | Fold 0 | Epoch 3/3 | Step 200/1642 | Loss: 0.156864 | LR: 0.00000199 | Adv:True
2025-09-22 07:45:41,273 | INFO | Fold 0 | Epoch 3/3 | Step 300/1642 | Loss: 0.127980 | LR: 0.00000174 | Adv:True
2025-09-22 07:46:28,154 | INFO | Fold 0 | Epoch 3/3 | Step 400/1642 | Loss: 0.131195 | LR: 0.00000151 | Adv:True
2025-09-22 07:47:15,286 | INFO | Fold 0 | Epoch 3/3 | Step 500/1642 | Loss: 0.079562 | LR: 0.00000129 | Adv:True
2025-09-22 07:48:02,631 | INFO | Fold 0 | Epoch 3/3 | Step 600/1642 | Loss: 0.054077 | LR: 0.00000108 | Adv:True
2025-09-22 07:48:50,724 | INFO | Fold 0 | Epoch 3/3 | Step 700/1642 | Loss: 0.045562 | LR: 0.00000089 | Adv:True
2025-09-22 07:49:42,428 | INFO | Fold 0 | Epoch 3/3 | Step 800/1642 | Loss: 0.191243 | LR: 0.00000072 | Adv:True
2025-09-22 07:50:34,675 | INFO | Fold 0 | Epoch 3/3 | Step 900/1642 | Loss: 0.187973 | LR: 0.00000056 | Adv:True
2025-09-22 07:51:27,067 | INFO | Fold 0 | Epoch 3/3 | Step 1000/1642 | Loss: 0.051521 | LR: 0.00000042 | Adv:True
2025-09-22 07:52:20,218 | INFO | Fold 0 | Epoch 3/3 | Step 1100/1642 | Loss: 0.153200 | LR: 0.00000030 | Adv:True
2025-09-22 07:53:13,897 | INFO | Fold 0 | Epoch 3/3 | Step 1200/1642 | Loss: 0.096852 | LR: 0.00000020 | Adv:True
2025-09-22 07:54:02,392 | INFO | Fold 0 | Epoch 3/3 | Step 1300/1642 | Loss: 0.197385 | LR: 0.00000012 | Adv:True
2025-09-22 07:54:48,617 | INFO | Fold 0 | Epoch 3/3 | Step 1400/1642 | Loss: 0.046360 | LR: 0.00000006 | Adv:True
2025-09-22 07:55:35,508 | INFO | Fold 0 | Epoch 3/3 | Step 1500/1642 | Loss: 0.126974 | LR: 0.00000002 | Adv:True
2025-09-22 07:56:22,675 | INFO | Fold 0 | Epoch 3/3 | Step 1600/1642 | Loss: 0.141693 | LR: 0.00000000 | Adv:True
2025-09-22 07:56:42,300 | INFO | Fold 0 | Epoch 3 done. Avg train loss: 0.099234 | Time: 803.25s
2025-09-22 07:56:42,300 | INFO | Applying EMA weights for evaluation.
2025-09-22 07:56:42,307 | INFO | Running validation inference (EMA-applied).
2025-09-22 07:56:52,962 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 07:56:52,967 | INFO | Fold 0 | Validation epoch 3: MSE(reg)=0.017394, MSE(exp)=0.016637, MSE(blend)=0.016815 | Pearson(reg)=0.869567, Pearson(exp)=0.869252, Pearson(blend)=0.870373
2025-09-22 07:56:52,967 | INFO | Fold 0 | New best validation Pearson (blend): 0.870373 at epoch 3
2025-09-22 07:56:52,967 | INFO | Applying EMA weights for evaluation.
2025-09-22 07:56:52,993 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 07:56:53,004 | INFO | Fold 0 | Generating OOF predictions with best EMA weights.
2025-09-22 07:56:53,004 | INFO | Running validation inference (EMA-applied).
2025-09-22 07:57:01,083 | INFO | Fold 0 | OOF Pearson (blend): 0.870373
2025-09-22 07:57:01,083 | INFO | Fold 0 | Running test inference.
2025-09-22 07:57:01,083 | INFO | Running test inference (TTA with swapped pairs).
2025-09-22 07:57:10,476 | INFO | ===== Fold 2/5 =====
2025-09-22 07:57:10,804 | INFO | Fold 1 -> Train batches: 1642, Valid batches: 206
2025-09-22 07:57:12,594 | INFO | Creating optimizer parameter groups with layer-wise LR decay.
2025-09-22 07:57:12,596 | INFO | Group 0: params=1, lr=0.00000832, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 1: params=2, lr=0.00000832, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 2: params=6, lr=0.00000876, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 3: params=10, lr=0.00000876, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 4: params=6, lr=0.00000922, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 5: params=10, lr=0.00000922, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 6: params=6, lr=0.00000971, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 7: params=10, lr=0.00000971, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 8: params=6, lr=0.00001022, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 9: params=10, lr=0.00001022, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 10: params=6, lr=0.00001075, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 11: params=10, lr=0.00001075, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 12: params=6, lr=0.00001132, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 13: params=10, lr=0.00001132, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 14: params=6, lr=0.00001192, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 15: params=10, lr=0.00001192, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 16: params=6, lr=0.00001254, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 17: params=10, lr=0.00001254, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 18: params=6, lr=0.00001320, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 19: params=10, lr=0.00001320, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 20: params=6, lr=0.00001390, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 21: params=10, lr=0.00001390, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 22: params=6, lr=0.00001463, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 23: params=10, lr=0.00001463, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 24: params=6, lr=0.00001540, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 25: params=10, lr=0.00001540, wd=0.0
2025-09-22 07:57:12,596 | INFO | Group 26: params=6, lr=0.00001621, wd=0.01
2025-09-22 07:57:12,596 | INFO | Group 27: params=10, lr=0.00001621, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 28: params=6, lr=0.00001706, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 29: params=10, lr=0.00001706, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 30: params=6, lr=0.00001796, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 31: params=10, lr=0.00001796, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 32: params=6, lr=0.00001891, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 33: params=10, lr=0.00001891, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 34: params=6, lr=0.00001990, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 35: params=10, lr=0.00001990, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 36: params=6, lr=0.00002095, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 37: params=10, lr=0.00002095, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 38: params=6, lr=0.00002205, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 39: params=10, lr=0.00002205, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 40: params=6, lr=0.00002321, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 41: params=10, lr=0.00002321, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 42: params=6, lr=0.00002444, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 43: params=10, lr=0.00002444, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 44: params=6, lr=0.00002572, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 45: params=10, lr=0.00002572, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 46: params=6, lr=0.00002708, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 47: params=10, lr=0.00002708, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 48: params=6, lr=0.00002850, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 49: params=10, lr=0.00002850, wd=0.0
2025-09-22 07:57:12,597 | INFO | Group 50: params=4, lr=0.00003000, wd=0.01
2025-09-22 07:57:12,597 | INFO | Group 51: params=4, lr=0.00003000, wd=0.0
2025-09-22 07:57:12,599 | INFO | Fold 1 -> Training steps: 4926, Warmup steps: 492, Adv start step: 492
2025-09-22 07:57:12,603 | INFO | Registering EMA shadow parameters.
2025-09-22 07:57:12,609 | INFO | Starting epoch 1/3 for fold 1.
2025-09-22 07:57:36,212 | INFO | Fold 1 | Epoch 1/3 | Step 100/1642 | Loss: 0.447426 | LR: 0.00000169 | Adv:False
2025-09-22 07:57:59,682 | INFO | Fold 1 | Epoch 1/3 | Step 200/1642 | Loss: 0.306140 | LR: 0.00000338 | Adv:False
2025-09-22 07:58:22,911 | INFO | Fold 1 | Epoch 1/3 | Step 300/1642 | Loss: 0.333635 | LR: 0.00000507 | Adv:False
2025-09-22 07:58:48,422 | INFO | Fold 1 | Epoch 1/3 | Step 400/1642 | Loss: 0.265385 | LR: 0.00000677 | Adv:False
2025-09-22 07:59:14,858 | INFO | Fold 1 | Epoch 1/3 | Step 500/1642 | Loss: 0.301243 | LR: 0.00000832 | Adv:True
2025-09-22 07:59:50,871 | INFO | Fold 1 | Epoch 1/3 | Step 600/1642 | Loss: 0.296424 | LR: 0.00000831 | Adv:True
2025-09-22 08:00:26,868 | INFO | Fold 1 | Epoch 1/3 | Step 700/1642 | Loss: 0.230289 | LR: 0.00000828 | Adv:True
2025-09-22 08:01:03,526 | INFO | Fold 1 | Epoch 1/3 | Step 800/1642 | Loss: 0.152737 | LR: 0.00000822 | Adv:True
2025-09-22 08:01:39,792 | INFO | Fold 1 | Epoch 1/3 | Step 900/1642 | Loss: 0.264013 | LR: 0.00000815 | Adv:True
2025-09-22 08:02:15,962 | INFO | Fold 1 | Epoch 1/3 | Step 1000/1642 | Loss: 0.330911 | LR: 0.00000806 | Adv:True
2025-09-22 08:02:52,446 | INFO | Fold 1 | Epoch 1/3 | Step 1100/1642 | Loss: 0.326476 | LR: 0.00000794 | Adv:True
2025-09-22 08:03:28,955 | INFO | Fold 1 | Epoch 1/3 | Step 1200/1642 | Loss: 0.193600 | LR: 0.00000781 | Adv:True
2025-09-22 08:04:05,361 | INFO | Fold 1 | Epoch 1/3 | Step 1300/1642 | Loss: 0.183804 | LR: 0.00000766 | Adv:True
2025-09-22 08:04:41,818 | INFO | Fold 1 | Epoch 1/3 | Step 1400/1642 | Loss: 0.274039 | LR: 0.00000749 | Adv:True
2025-09-22 08:05:18,261 | INFO | Fold 1 | Epoch 1/3 | Step 1500/1642 | Loss: 0.247184 | LR: 0.00000730 | Adv:True
2025-09-22 08:05:54,570 | INFO | Fold 1 | Epoch 1/3 | Step 1600/1642 | Loss: 0.251080 | LR: 0.00000710 | Adv:True
2025-09-22 08:06:09,631 | INFO | Fold 1 | Epoch 1 done. Avg train loss: 0.273455 | Time: 537.02s
2025-09-22 08:06:09,631 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:06:09,638 | INFO | Running validation inference (EMA-applied).
2025-09-22 08:06:19,422 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:06:19,430 | INFO | Fold 1 | Validation epoch 1: MSE(reg)=0.020491, MSE(exp)=0.021502, MSE(blend)=0.019672 | Pearson(reg)=0.838469, Pearson(exp)=0.842425, Pearson(blend)=0.842837
2025-09-22 08:06:19,430 | INFO | Fold 1 | New best validation Pearson (blend): 0.842837 at epoch 1
2025-09-22 08:06:19,430 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:06:19,459 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:06:19,463 | INFO | Starting epoch 2/3 for fold 1.
2025-09-22 08:06:55,560 | INFO | Fold 1 | Epoch 2/3 | Step 100/1642 | Loss: 0.129115 | LR: 0.00000679 | Adv:True
2025-09-22 08:07:31,781 | INFO | Fold 1 | Epoch 2/3 | Step 200/1642 | Loss: 0.235071 | LR: 0.00000656 | Adv:True
2025-09-22 08:08:08,099 | INFO | Fold 1 | Epoch 2/3 | Step 300/1642 | Loss: 0.109551 | LR: 0.00000631 | Adv:True
2025-09-22 08:08:44,160 | INFO | Fold 1 | Epoch 2/3 | Step 400/1642 | Loss: 0.158504 | LR: 0.00000605 | Adv:True
2025-09-22 08:09:20,137 | INFO | Fold 1 | Epoch 2/3 | Step 500/1642 | Loss: 0.182563 | LR: 0.00000579 | Adv:True
2025-09-22 08:09:56,466 | INFO | Fold 1 | Epoch 2/3 | Step 600/1642 | Loss: 0.109065 | LR: 0.00000551 | Adv:True
2025-09-22 08:10:32,894 | INFO | Fold 1 | Epoch 2/3 | Step 700/1642 | Loss: 0.133841 | LR: 0.00000523 | Adv:True
2025-09-22 08:11:08,951 | INFO | Fold 1 | Epoch 2/3 | Step 800/1642 | Loss: 0.217438 | LR: 0.00000494 | Adv:True
2025-09-22 08:11:45,147 | INFO | Fold 1 | Epoch 2/3 | Step 900/1642 | Loss: 0.146122 | LR: 0.00000465 | Adv:True
2025-09-22 08:12:21,812 | INFO | Fold 1 | Epoch 2/3 | Step 1000/1642 | Loss: 0.088904 | LR: 0.00000436 | Adv:True
2025-09-22 08:12:58,295 | INFO | Fold 1 | Epoch 2/3 | Step 1100/1642 | Loss: 0.105662 | LR: 0.00000406 | Adv:True
2025-09-22 08:13:36,443 | INFO | Fold 1 | Epoch 2/3 | Step 1200/1642 | Loss: 0.214156 | LR: 0.00000377 | Adv:True
2025-09-22 08:14:09,910 | INFO | Fold 1 | Epoch 2/3 | Step 1300/1642 | Loss: 0.105875 | LR: 0.00000348 | Adv:True
2025-09-22 08:14:43,701 | INFO | Fold 1 | Epoch 2/3 | Step 1400/1642 | Loss: 0.114327 | LR: 0.00000319 | Adv:True
2025-09-22 08:15:17,423 | INFO | Fold 1 | Epoch 2/3 | Step 1500/1642 | Loss: 0.109508 | LR: 0.00000290 | Adv:True
2025-09-22 08:15:50,840 | INFO | Fold 1 | Epoch 2/3 | Step 1600/1642 | Loss: 0.193859 | LR: 0.00000263 | Adv:True
2025-09-22 08:16:04,773 | INFO | Fold 1 | Epoch 2 done. Avg train loss: 0.160124 | Time: 585.31s
2025-09-22 08:16:04,773 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:16:04,779 | INFO | Running validation inference (EMA-applied).
2025-09-22 08:16:12,830 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:16:12,836 | INFO | Fold 1 | Validation epoch 2: MSE(reg)=0.017816, MSE(exp)=0.016675, MSE(blend)=0.016896 | Pearson(reg)=0.866452, Pearson(exp)=0.867274, Pearson(blend)=0.867781
2025-09-22 08:16:12,836 | INFO | Fold 1 | New best validation Pearson (blend): 0.867781 at epoch 2
2025-09-22 08:16:12,836 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:16:12,863 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:16:12,866 | INFO | Starting epoch 3/3 for fold 1.
2025-09-22 08:16:46,408 | INFO | Fold 1 | Epoch 3/3 | Step 100/1642 | Loss: 0.106490 | LR: 0.00000225 | Adv:True
2025-09-22 08:17:20,076 | INFO | Fold 1 | Epoch 3/3 | Step 200/1642 | Loss: 0.172269 | LR: 0.00000199 | Adv:True
2025-09-22 08:17:53,937 | INFO | Fold 1 | Epoch 3/3 | Step 300/1642 | Loss: 0.121557 | LR: 0.00000174 | Adv:True
2025-09-22 08:18:27,672 | INFO | Fold 1 | Epoch 3/3 | Step 400/1642 | Loss: 0.162031 | LR: 0.00000151 | Adv:True
2025-09-22 08:19:01,763 | INFO | Fold 1 | Epoch 3/3 | Step 500/1642 | Loss: 0.127307 | LR: 0.00000129 | Adv:True
2025-09-22 08:19:35,737 | INFO | Fold 1 | Epoch 3/3 | Step 600/1642 | Loss: 0.082622 | LR: 0.00000108 | Adv:True
2025-09-22 08:20:10,023 | INFO | Fold 1 | Epoch 3/3 | Step 700/1642 | Loss: 0.084603 | LR: 0.00000089 | Adv:True
2025-09-22 08:20:45,595 | INFO | Fold 1 | Epoch 3/3 | Step 800/1642 | Loss: 0.183958 | LR: 0.00000072 | Adv:True
2025-09-22 08:21:21,813 | INFO | Fold 1 | Epoch 3/3 | Step 900/1642 | Loss: 0.064211 | LR: 0.00000056 | Adv:True
2025-09-22 08:21:58,156 | INFO | Fold 1 | Epoch 3/3 | Step 1000/1642 | Loss: 0.087521 | LR: 0.00000042 | Adv:True
2025-09-22 08:22:34,599 | INFO | Fold 1 | Epoch 3/3 | Step 1100/1642 | Loss: 0.068862 | LR: 0.00000030 | Adv:True
2025-09-22 08:23:11,131 | INFO | Fold 1 | Epoch 3/3 | Step 1200/1642 | Loss: 0.092719 | LR: 0.00000020 | Adv:True
2025-09-22 08:23:47,482 | INFO | Fold 1 | Epoch 3/3 | Step 1300/1642 | Loss: 0.124899 | LR: 0.00000012 | Adv:True
2025-09-22 08:24:23,559 | INFO | Fold 1 | Epoch 3/3 | Step 1400/1642 | Loss: 0.101307 | LR: 0.00000006 | Adv:True
2025-09-22 08:24:59,916 | INFO | Fold 1 | Epoch 3/3 | Step 1500/1642 | Loss: 0.148718 | LR: 0.00000002 | Adv:True
2025-09-22 08:25:36,549 | INFO | Fold 1 | Epoch 3/3 | Step 1600/1642 | Loss: 0.057482 | LR: 0.00000000 | Adv:True
2025-09-22 08:25:51,760 | INFO | Fold 1 | Epoch 3 done. Avg train loss: 0.099397 | Time: 578.89s
2025-09-22 08:25:51,760 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:25:51,767 | INFO | Running validation inference (EMA-applied).
2025-09-22 08:26:00,988 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:26:00,992 | INFO | Fold 1 | Validation epoch 3: MSE(reg)=0.017487, MSE(exp)=0.016709, MSE(blend)=0.016903 | Pearson(reg)=0.868347, Pearson(exp)=0.868655, Pearson(blend)=0.869446
2025-09-22 08:26:00,992 | INFO | Fold 1 | New best validation Pearson (blend): 0.869446 at epoch 3
2025-09-22 08:26:00,993 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:26:01,019 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:26:01,030 | INFO | Fold 1 | Generating OOF predictions with best EMA weights.
2025-09-22 08:26:01,030 | INFO | Running validation inference (EMA-applied).
2025-09-22 08:26:10,265 | INFO | Fold 1 | OOF Pearson (blend): 0.869446
2025-09-22 08:26:10,265 | INFO | Fold 1 | Running test inference.
2025-09-22 08:26:10,265 | INFO | Running test inference (TTA with swapped pairs).
2025-09-22 08:26:20,300 | INFO | ===== Fold 3/5 =====
2025-09-22 08:26:20,587 | INFO | Fold 2 -> Train batches: 1642, Valid batches: 206
2025-09-22 08:26:22,311 | INFO | Creating optimizer parameter groups with layer-wise LR decay.
2025-09-22 08:26:22,313 | INFO | Group 0: params=1, lr=0.00000832, wd=0.01
2025-09-22 08:26:22,313 | INFO | Group 1: params=2, lr=0.00000832, wd=0.0
2025-09-22 08:26:22,313 | INFO | Group 2: params=6, lr=0.00000876, wd=0.01
2025-09-22 08:26:22,313 | INFO | Group 3: params=10, lr=0.00000876, wd=0.0
2025-09-22 08:26:22,313 | INFO | Group 4: params=6, lr=0.00000922, wd=0.01
2025-09-22 08:26:22,313 | INFO | Group 5: params=10, lr=0.00000922, wd=0.0
2025-09-22 08:26:22,313 | INFO | Group 6: params=6, lr=0.00000971, wd=0.01
2025-09-22 08:26:22,313 | INFO | Group 7: params=10, lr=0.00000971, wd=0.0
2025-09-22 08:26:22,313 | INFO | Group 8: params=6, lr=0.00001022, wd=0.01
2025-09-22 08:26:22,313 | INFO | Group 9: params=10, lr=0.00001022, wd=0.0
2025-09-22 08:26:22,313 | INFO | Group 10: params=6, lr=0.00001075, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 11: params=10, lr=0.00001075, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 12: params=6, lr=0.00001132, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 13: params=10, lr=0.00001132, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 14: params=6, lr=0.00001192, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 15: params=10, lr=0.00001192, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 16: params=6, lr=0.00001254, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 17: params=10, lr=0.00001254, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 18: params=6, lr=0.00001320, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 19: params=10, lr=0.00001320, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 20: params=6, lr=0.00001390, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 21: params=10, lr=0.00001390, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 22: params=6, lr=0.00001463, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 23: params=10, lr=0.00001463, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 24: params=6, lr=0.00001540, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 25: params=10, lr=0.00001540, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 26: params=6, lr=0.00001621, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 27: params=10, lr=0.00001621, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 28: params=6, lr=0.00001706, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 29: params=10, lr=0.00001706, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 30: params=6, lr=0.00001796, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 31: params=10, lr=0.00001796, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 32: params=6, lr=0.00001891, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 33: params=10, lr=0.00001891, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 34: params=6, lr=0.00001990, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 35: params=10, lr=0.00001990, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 36: params=6, lr=0.00002095, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 37: params=10, lr=0.00002095, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 38: params=6, lr=0.00002205, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 39: params=10, lr=0.00002205, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 40: params=6, lr=0.00002321, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 41: params=10, lr=0.00002321, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 42: params=6, lr=0.00002444, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 43: params=10, lr=0.00002444, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 44: params=6, lr=0.00002572, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 45: params=10, lr=0.00002572, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 46: params=6, lr=0.00002708, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 47: params=10, lr=0.00002708, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 48: params=6, lr=0.00002850, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 49: params=10, lr=0.00002850, wd=0.0
2025-09-22 08:26:22,314 | INFO | Group 50: params=4, lr=0.00003000, wd=0.01
2025-09-22 08:26:22,314 | INFO | Group 51: params=4, lr=0.00003000, wd=0.0
2025-09-22 08:26:22,316 | INFO | Fold 2 -> Training steps: 4926, Warmup steps: 492, Adv start step: 492
2025-09-22 08:26:22,320 | INFO | Registering EMA shadow parameters.
2025-09-22 08:26:22,326 | INFO | Starting epoch 1/3 for fold 2.
2025-09-22 08:26:48,065 | INFO | Fold 2 | Epoch 1/3 | Step 100/1642 | Loss: 0.397707 | LR: 0.00000169 | Adv:False
2025-09-22 08:27:13,644 | INFO | Fold 2 | Epoch 1/3 | Step 200/1642 | Loss: 0.316031 | LR: 0.00000338 | Adv:False
2025-09-22 08:27:39,371 | INFO | Fold 2 | Epoch 1/3 | Step 300/1642 | Loss: 0.284728 | LR: 0.00000507 | Adv:False
2025-09-22 08:28:05,506 | INFO | Fold 2 | Epoch 1/3 | Step 400/1642 | Loss: 0.281467 | LR: 0.00000677 | Adv:False
2025-09-22 08:28:32,076 | INFO | Fold 2 | Epoch 1/3 | Step 500/1642 | Loss: 0.218142 | LR: 0.00000832 | Adv:True
2025-09-22 08:29:08,949 | INFO | Fold 2 | Epoch 1/3 | Step 600/1642 | Loss: 0.170275 | LR: 0.00000831 | Adv:True
2025-09-22 08:29:45,521 | INFO | Fold 2 | Epoch 1/3 | Step 700/1642 | Loss: 0.224733 | LR: 0.00000828 | Adv:True
2025-09-22 08:30:22,422 | INFO | Fold 2 | Epoch 1/3 | Step 800/1642 | Loss: 0.180014 | LR: 0.00000822 | Adv:True
2025-09-22 08:30:59,132 | INFO | Fold 2 | Epoch 1/3 | Step 900/1642 | Loss: 0.281062 | LR: 0.00000815 | Adv:True
2025-09-22 08:31:36,051 | INFO | Fold 2 | Epoch 1/3 | Step 1000/1642 | Loss: 0.259141 | LR: 0.00000806 | Adv:True
2025-09-22 08:32:12,754 | INFO | Fold 2 | Epoch 1/3 | Step 1100/1642 | Loss: 0.182926 | LR: 0.00000794 | Adv:True
2025-09-22 08:32:49,558 | INFO | Fold 2 | Epoch 1/3 | Step 1200/1642 | Loss: 0.171799 | LR: 0.00000781 | Adv:True
2025-09-22 08:33:26,285 | INFO | Fold 2 | Epoch 1/3 | Step 1300/1642 | Loss: 0.217668 | LR: 0.00000766 | Adv:True
2025-09-22 08:34:02,653 | INFO | Fold 2 | Epoch 1/3 | Step 1400/1642 | Loss: 0.193222 | LR: 0.00000749 | Adv:True
2025-09-22 08:34:39,482 | INFO | Fold 2 | Epoch 1/3 | Step 1500/1642 | Loss: 0.189900 | LR: 0.00000730 | Adv:True
2025-09-22 08:35:18,952 | INFO | Fold 2 | Epoch 1/3 | Step 1600/1642 | Loss: 0.304554 | LR: 0.00000710 | Adv:True
2025-09-22 08:35:34,910 | INFO | Fold 2 | Epoch 1 done. Avg train loss: 0.276855 | Time: 552.58s
2025-09-22 08:35:34,911 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:35:34,917 | INFO | Running validation inference (EMA-applied).
2025-09-22 08:35:43,408 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:35:43,417 | INFO | Fold 2 | Validation epoch 1: MSE(reg)=0.020053, MSE(exp)=0.022148, MSE(blend)=0.019958 | Pearson(reg)=0.843827, Pearson(exp)=0.840488, Pearson(blend)=0.844477
2025-09-22 08:35:43,417 | INFO | Fold 2 | New best validation Pearson (blend): 0.844477 at epoch 1
2025-09-22 08:35:43,417 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:35:43,445 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:35:43,450 | INFO | Starting epoch 2/3 for fold 2.
2025-09-22 08:36:18,120 | INFO | Fold 2 | Epoch 2/3 | Step 100/1642 | Loss: 0.072111 | LR: 0.00000679 | Adv:True
2025-09-22 08:36:52,520 | INFO | Fold 2 | Epoch 2/3 | Step 200/1642 | Loss: 0.106684 | LR: 0.00000656 | Adv:True
2025-09-22 08:37:27,260 | INFO | Fold 2 | Epoch 2/3 | Step 300/1642 | Loss: 0.224261 | LR: 0.00000631 | Adv:True
2025-09-22 08:38:02,192 | INFO | Fold 2 | Epoch 2/3 | Step 400/1642 | Loss: 0.223678 | LR: 0.00000605 | Adv:True
2025-09-22 08:38:37,508 | INFO | Fold 2 | Epoch 2/3 | Step 500/1642 | Loss: 0.057434 | LR: 0.00000579 | Adv:True
2025-09-22 08:39:12,567 | INFO | Fold 2 | Epoch 2/3 | Step 600/1642 | Loss: 0.201310 | LR: 0.00000551 | Adv:True
2025-09-22 08:39:47,952 | INFO | Fold 2 | Epoch 2/3 | Step 700/1642 | Loss: 0.071729 | LR: 0.00000523 | Adv:True
2025-09-22 08:40:23,273 | INFO | Fold 2 | Epoch 2/3 | Step 800/1642 | Loss: 0.182233 | LR: 0.00000494 | Adv:True
2025-09-22 08:40:58,675 | INFO | Fold 2 | Epoch 2/3 | Step 900/1642 | Loss: 0.118343 | LR: 0.00000465 | Adv:True
2025-09-22 08:41:35,485 | INFO | Fold 2 | Epoch 2/3 | Step 1000/1642 | Loss: 0.082459 | LR: 0.00000436 | Adv:True
2025-09-22 08:42:12,826 | INFO | Fold 2 | Epoch 2/3 | Step 1100/1642 | Loss: 0.279065 | LR: 0.00000406 | Adv:True
2025-09-22 08:42:50,001 | INFO | Fold 2 | Epoch 2/3 | Step 1200/1642 | Loss: 0.148782 | LR: 0.00000377 | Adv:True
2025-09-22 08:43:26,781 | INFO | Fold 2 | Epoch 2/3 | Step 1300/1642 | Loss: 0.144519 | LR: 0.00000348 | Adv:True
2025-09-22 08:44:03,681 | INFO | Fold 2 | Epoch 2/3 | Step 1400/1642 | Loss: 0.073845 | LR: 0.00000319 | Adv:True
2025-09-22 08:44:39,286 | INFO | Fold 2 | Epoch 2/3 | Step 1500/1642 | Loss: 0.194603 | LR: 0.00000290 | Adv:True
2025-09-22 08:45:13,783 | INFO | Fold 2 | Epoch 2/3 | Step 1600/1642 | Loss: 0.269226 | LR: 0.00000263 | Adv:True
2025-09-22 08:45:28,270 | INFO | Fold 2 | Epoch 2 done. Avg train loss: 0.161358 | Time: 584.82s
2025-09-22 08:45:28,271 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:45:28,277 | INFO | Running validation inference (EMA-applied).
2025-09-22 08:45:36,363 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:45:36,369 | INFO | Fold 2 | Validation epoch 2: MSE(reg)=0.017641, MSE(exp)=0.016631, MSE(blend)=0.016805 | Pearson(reg)=0.868474, Pearson(exp)=0.867805, Pearson(blend)=0.869060
2025-09-22 08:45:36,369 | INFO | Fold 2 | New best validation Pearson (blend): 0.869060 at epoch 2
2025-09-22 08:45:36,369 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:45:36,396 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:45:36,400 | INFO | Starting epoch 3/3 for fold 2.
2025-09-22 08:46:12,039 | INFO | Fold 2 | Epoch 3/3 | Step 100/1642 | Loss: 0.142743 | LR: 0.00000225 | Adv:True
2025-09-22 08:46:47,227 | INFO | Fold 2 | Epoch 3/3 | Step 200/1642 | Loss: 0.143526 | LR: 0.00000199 | Adv:True
2025-09-22 08:47:22,268 | INFO | Fold 2 | Epoch 3/3 | Step 300/1642 | Loss: 0.089789 | LR: 0.00000174 | Adv:True
2025-09-22 08:47:57,063 | INFO | Fold 2 | Epoch 3/3 | Step 400/1642 | Loss: 0.084276 | LR: 0.00000151 | Adv:True
2025-09-22 08:48:32,000 | INFO | Fold 2 | Epoch 3/3 | Step 500/1642 | Loss: 0.066503 | LR: 0.00000129 | Adv:True
2025-09-22 08:49:06,669 | INFO | Fold 2 | Epoch 3/3 | Step 600/1642 | Loss: 0.084912 | LR: 0.00000108 | Adv:True
2025-09-22 08:49:41,280 | INFO | Fold 2 | Epoch 3/3 | Step 700/1642 | Loss: 0.102564 | LR: 0.00000089 | Adv:True
2025-09-22 08:50:16,024 | INFO | Fold 2 | Epoch 3/3 | Step 800/1642 | Loss: 0.175348 | LR: 0.00000072 | Adv:True
2025-09-22 08:50:50,976 | INFO | Fold 2 | Epoch 3/3 | Step 900/1642 | Loss: 0.037332 | LR: 0.00000056 | Adv:True
2025-09-22 08:51:26,080 | INFO | Fold 2 | Epoch 3/3 | Step 1000/1642 | Loss: 0.069318 | LR: 0.00000042 | Adv:True
2025-09-22 08:52:01,259 | INFO | Fold 2 | Epoch 3/3 | Step 1100/1642 | Loss: 0.192660 | LR: 0.00000030 | Adv:True
2025-09-22 08:52:36,459 | INFO | Fold 2 | Epoch 3/3 | Step 1200/1642 | Loss: 0.033605 | LR: 0.00000020 | Adv:True
2025-09-22 08:53:11,825 | INFO | Fold 2 | Epoch 3/3 | Step 1300/1642 | Loss: 0.125528 | LR: 0.00000012 | Adv:True
2025-09-22 08:53:46,663 | INFO | Fold 2 | Epoch 3/3 | Step 1400/1642 | Loss: 0.029987 | LR: 0.00000006 | Adv:True
2025-09-22 08:54:21,091 | INFO | Fold 2 | Epoch 3/3 | Step 1500/1642 | Loss: 0.153241 | LR: 0.00000002 | Adv:True
2025-09-22 08:54:56,091 | INFO | Fold 2 | Epoch 3/3 | Step 1600/1642 | Loss: 0.045192 | LR: 0.00000000 | Adv:True
2025-09-22 08:55:10,527 | INFO | Fold 2 | Epoch 3 done. Avg train loss: 0.100788 | Time: 574.13s
2025-09-22 08:55:10,527 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:55:10,534 | INFO | Running validation inference (EMA-applied).
2025-09-22 08:55:18,571 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:55:18,575 | INFO | Fold 2 | Validation epoch 3: MSE(reg)=0.017234, MSE(exp)=0.016684, MSE(blend)=0.016774 | Pearson(reg)=0.869952, Pearson(exp)=0.869103, Pearson(blend)=0.870435
2025-09-22 08:55:18,575 | INFO | Fold 2 | New best validation Pearson (blend): 0.870435 at epoch 3
2025-09-22 08:55:18,576 | INFO | Applying EMA weights for evaluation.
2025-09-22 08:55:18,602 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 08:55:18,613 | INFO | Fold 2 | Generating OOF predictions with best EMA weights.
2025-09-22 08:55:18,613 | INFO | Running validation inference (EMA-applied).
2025-09-22 08:55:26,626 | INFO | Fold 2 | OOF Pearson (blend): 0.870435
2025-09-22 08:55:26,626 | INFO | Fold 2 | Running test inference.
2025-09-22 08:55:26,626 | INFO | Running test inference (TTA with swapped pairs).
2025-09-22 08:55:35,455 | INFO | ===== Fold 4/5 =====
2025-09-22 08:55:35,788 | INFO | Fold 3 -> Train batches: 1642, Valid batches: 206
2025-09-22 08:55:37,136 | INFO | Creating optimizer parameter groups with layer-wise LR decay.
2025-09-22 08:55:37,138 | INFO | Group 0: params=1, lr=0.00000832, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 1: params=2, lr=0.00000832, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 2: params=6, lr=0.00000876, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 3: params=10, lr=0.00000876, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 4: params=6, lr=0.00000922, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 5: params=10, lr=0.00000922, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 6: params=6, lr=0.00000971, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 7: params=10, lr=0.00000971, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 8: params=6, lr=0.00001022, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 9: params=10, lr=0.00001022, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 10: params=6, lr=0.00001075, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 11: params=10, lr=0.00001075, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 12: params=6, lr=0.00001132, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 13: params=10, lr=0.00001132, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 14: params=6, lr=0.00001192, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 15: params=10, lr=0.00001192, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 16: params=6, lr=0.00001254, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 17: params=10, lr=0.00001254, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 18: params=6, lr=0.00001320, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 19: params=10, lr=0.00001320, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 20: params=6, lr=0.00001390, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 21: params=10, lr=0.00001390, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 22: params=6, lr=0.00001463, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 23: params=10, lr=0.00001463, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 24: params=6, lr=0.00001540, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 25: params=10, lr=0.00001540, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 26: params=6, lr=0.00001621, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 27: params=10, lr=0.00001621, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 28: params=6, lr=0.00001706, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 29: params=10, lr=0.00001706, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 30: params=6, lr=0.00001796, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 31: params=10, lr=0.00001796, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 32: params=6, lr=0.00001891, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 33: params=10, lr=0.00001891, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 34: params=6, lr=0.00001990, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 35: params=10, lr=0.00001990, wd=0.0
2025-09-22 08:55:37,138 | INFO | Group 36: params=6, lr=0.00002095, wd=0.01
2025-09-22 08:55:37,138 | INFO | Group 37: params=10, lr=0.00002095, wd=0.0
2025-09-22 08:55:37,139 | INFO | Group 38: params=6, lr=0.00002205, wd=0.01
2025-09-22 08:55:37,139 | INFO | Group 39: params=10, lr=0.00002205, wd=0.0
2025-09-22 08:55:37,139 | INFO | Group 40: params=6, lr=0.00002321, wd=0.01
2025-09-22 08:55:37,139 | INFO | Group 41: params=10, lr=0.00002321, wd=0.0
2025-09-22 08:55:37,139 | INFO | Group 42: params=6, lr=0.00002444, wd=0.01
2025-09-22 08:55:37,139 | INFO | Group 43: params=10, lr=0.00002444, wd=0.0
2025-09-22 08:55:37,139 | INFO | Group 44: params=6, lr=0.00002572, wd=0.01
2025-09-22 08:55:37,139 | INFO | Group 45: params=10, lr=0.00002572, wd=0.0
2025-09-22 08:55:37,139 | INFO | Group 46: params=6, lr=0.00002708, wd=0.01
2025-09-22 08:55:37,139 | INFO | Group 47: params=10, lr=0.00002708, wd=0.0
2025-09-22 08:55:37,139 | INFO | Group 48: params=6, lr=0.00002850, wd=0.01
2025-09-22 08:55:37,139 | INFO | Group 49: params=10, lr=0.00002850, wd=0.0
2025-09-22 08:55:37,139 | INFO | Group 50: params=4, lr=0.00003000, wd=0.01
2025-09-22 08:55:37,139 | INFO | Group 51: params=4, lr=0.00003000, wd=0.0
2025-09-22 08:55:37,140 | INFO | Fold 3 -> Training steps: 4926, Warmup steps: 492, Adv start step: 492
2025-09-22 08:55:37,144 | INFO | Registering EMA shadow parameters.
2025-09-22 08:55:37,150 | INFO | Starting epoch 1/3 for fold 3.
2025-09-22 08:56:02,484 | INFO | Fold 3 | Epoch 1/3 | Step 100/1642 | Loss: 0.447822 | LR: 0.00000169 | Adv:False
2025-09-22 08:56:26,198 | INFO | Fold 3 | Epoch 1/3 | Step 200/1642 | Loss: 0.422127 | LR: 0.00000338 | Adv:False
2025-09-22 08:56:49,935 | INFO | Fold 3 | Epoch 1/3 | Step 300/1642 | Loss: 0.359719 | LR: 0.00000507 | Adv:False
2025-09-22 08:57:14,195 | INFO | Fold 3 | Epoch 1/3 | Step 400/1642 | Loss: 0.270447 | LR: 0.00000677 | Adv:False
2025-09-22 08:57:38,766 | INFO | Fold 3 | Epoch 1/3 | Step 500/1642 | Loss: 0.347752 | LR: 0.00000832 | Adv:True
2025-09-22 08:58:13,120 | INFO | Fold 3 | Epoch 1/3 | Step 600/1642 | Loss: 0.268891 | LR: 0.00000831 | Adv:True
2025-09-22 08:58:47,861 | INFO | Fold 3 | Epoch 1/3 | Step 700/1642 | Loss: 0.293501 | LR: 0.00000828 | Adv:True
2025-09-22 08:59:22,190 | INFO | Fold 3 | Epoch 1/3 | Step 800/1642 | Loss: 0.158332 | LR: 0.00000822 | Adv:True
2025-09-22 08:59:56,233 | INFO | Fold 3 | Epoch 1/3 | Step 900/1642 | Loss: 0.178752 | LR: 0.00000815 | Adv:True
2025-09-22 09:00:30,267 | INFO | Fold 3 | Epoch 1/3 | Step 1000/1642 | Loss: 0.216916 | LR: 0.00000806 | Adv:True
2025-09-22 09:01:04,527 | INFO | Fold 3 | Epoch 1/3 | Step 1100/1642 | Loss: 0.158818 | LR: 0.00000794 | Adv:True
2025-09-22 09:01:39,275 | INFO | Fold 3 | Epoch 1/3 | Step 1200/1642 | Loss: 0.147081 | LR: 0.00000781 | Adv:True
2025-09-22 09:02:13,868 | INFO | Fold 3 | Epoch 1/3 | Step 1300/1642 | Loss: 0.172647 | LR: 0.00000766 | Adv:True
2025-09-22 09:02:48,162 | INFO | Fold 3 | Epoch 1/3 | Step 1400/1642 | Loss: 0.286969 | LR: 0.00000749 | Adv:True
2025-09-22 09:03:22,640 | INFO | Fold 3 | Epoch 1/3 | Step 1500/1642 | Loss: 0.289118 | LR: 0.00000730 | Adv:True
2025-09-22 09:03:57,190 | INFO | Fold 3 | Epoch 1/3 | Step 1600/1642 | Loss: 0.321867 | LR: 0.00000710 | Adv:True
2025-09-22 09:04:11,608 | INFO | Fold 3 | Epoch 1 done. Avg train loss: 0.282334 | Time: 514.46s
2025-09-22 09:04:11,609 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:04:11,615 | INFO | Running validation inference (EMA-applied).
2025-09-22 09:04:20,007 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:04:20,014 | INFO | Fold 3 | Validation epoch 1: MSE(reg)=0.029956, MSE(exp)=0.022233, MSE(blend)=0.021644 | Pearson(reg)=0.843877, Pearson(exp)=0.841110, Pearson(blend)=0.845110
2025-09-22 09:04:20,014 | INFO | Fold 3 | New best validation Pearson (blend): 0.845110 at epoch 1
2025-09-22 09:04:20,015 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:04:20,043 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:04:20,047 | INFO | Starting epoch 2/3 for fold 3.
2025-09-22 09:04:54,330 | INFO | Fold 3 | Epoch 2/3 | Step 100/1642 | Loss: 0.131226 | LR: 0.00000679 | Adv:True
2025-09-22 09:05:28,672 | INFO | Fold 3 | Epoch 2/3 | Step 200/1642 | Loss: 0.256970 | LR: 0.00000656 | Adv:True
2025-09-22 09:06:03,874 | INFO | Fold 3 | Epoch 2/3 | Step 300/1642 | Loss: 0.088383 | LR: 0.00000631 | Adv:True
2025-09-22 09:06:38,391 | INFO | Fold 3 | Epoch 2/3 | Step 400/1642 | Loss: 0.263555 | LR: 0.00000605 | Adv:True
2025-09-22 09:07:12,619 | INFO | Fold 3 | Epoch 2/3 | Step 500/1642 | Loss: 0.161475 | LR: 0.00000579 | Adv:True
2025-09-22 09:07:47,059 | INFO | Fold 3 | Epoch 2/3 | Step 600/1642 | Loss: 0.090140 | LR: 0.00000551 | Adv:True
2025-09-22 09:08:21,319 | INFO | Fold 3 | Epoch 2/3 | Step 700/1642 | Loss: 0.291109 | LR: 0.00000523 | Adv:True
2025-09-22 09:08:56,394 | INFO | Fold 3 | Epoch 2/3 | Step 800/1642 | Loss: 0.072334 | LR: 0.00000494 | Adv:True
2025-09-22 09:09:30,800 | INFO | Fold 3 | Epoch 2/3 | Step 900/1642 | Loss: 0.200201 | LR: 0.00000465 | Adv:True
2025-09-22 09:10:05,401 | INFO | Fold 3 | Epoch 2/3 | Step 1000/1642 | Loss: 0.205945 | LR: 0.00000436 | Adv:True
2025-09-22 09:10:39,651 | INFO | Fold 3 | Epoch 2/3 | Step 1100/1642 | Loss: 0.116631 | LR: 0.00000406 | Adv:True
2025-09-22 09:11:14,013 | INFO | Fold 3 | Epoch 2/3 | Step 1200/1642 | Loss: 0.127189 | LR: 0.00000377 | Adv:True
2025-09-22 09:11:48,466 | INFO | Fold 3 | Epoch 2/3 | Step 1300/1642 | Loss: 0.100402 | LR: 0.00000348 | Adv:True
2025-09-22 09:12:23,015 | INFO | Fold 3 | Epoch 2/3 | Step 1400/1642 | Loss: 0.160227 | LR: 0.00000319 | Adv:True
2025-09-22 09:12:57,097 | INFO | Fold 3 | Epoch 2/3 | Step 1500/1642 | Loss: 0.076055 | LR: 0.00000290 | Adv:True
2025-09-22 09:13:31,315 | INFO | Fold 3 | Epoch 2/3 | Step 1600/1642 | Loss: 0.274076 | LR: 0.00000263 | Adv:True
2025-09-22 09:13:45,689 | INFO | Fold 3 | Epoch 2 done. Avg train loss: 0.162340 | Time: 565.64s
2025-09-22 09:13:45,689 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:13:45,695 | INFO | Running validation inference (EMA-applied).
2025-09-22 09:13:53,569 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:13:53,574 | INFO | Fold 3 | Validation epoch 2: MSE(reg)=0.018009, MSE(exp)=0.016502, MSE(blend)=0.016785 | Pearson(reg)=0.868076, Pearson(exp)=0.868778, Pearson(blend)=0.869317
2025-09-22 09:13:53,574 | INFO | Fold 3 | New best validation Pearson (blend): 0.869317 at epoch 2
2025-09-22 09:13:53,574 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:13:53,600 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:13:53,603 | INFO | Starting epoch 3/3 for fold 3.
2025-09-22 09:14:28,157 | INFO | Fold 3 | Epoch 3/3 | Step 100/1642 | Loss: 0.049900 | LR: 0.00000225 | Adv:True
2025-09-22 09:15:02,633 | INFO | Fold 3 | Epoch 3/3 | Step 200/1642 | Loss: 0.049226 | LR: 0.00000199 | Adv:True
2025-09-22 09:15:37,853 | INFO | Fold 3 | Epoch 3/3 | Step 300/1642 | Loss: 0.110844 | LR: 0.00000174 | Adv:True
2025-09-22 09:16:13,201 | INFO | Fold 3 | Epoch 3/3 | Step 400/1642 | Loss: 0.038188 | LR: 0.00000151 | Adv:True
2025-09-22 09:16:48,822 | INFO | Fold 3 | Epoch 3/3 | Step 500/1642 | Loss: 0.057204 | LR: 0.00000129 | Adv:True
2025-09-22 09:17:23,675 | INFO | Fold 3 | Epoch 3/3 | Step 600/1642 | Loss: 0.069186 | LR: 0.00000108 | Adv:True
2025-09-22 09:17:58,025 | INFO | Fold 3 | Epoch 3/3 | Step 700/1642 | Loss: 0.070755 | LR: 0.00000089 | Adv:True
2025-09-22 09:18:32,754 | INFO | Fold 3 | Epoch 3/3 | Step 800/1642 | Loss: 0.060501 | LR: 0.00000072 | Adv:True
2025-09-22 09:19:07,992 | INFO | Fold 3 | Epoch 3/3 | Step 900/1642 | Loss: 0.149390 | LR: 0.00000056 | Adv:True
2025-09-22 09:19:42,545 | INFO | Fold 3 | Epoch 3/3 | Step 1000/1642 | Loss: 0.160719 | LR: 0.00000042 | Adv:True
2025-09-22 09:20:17,359 | INFO | Fold 3 | Epoch 3/3 | Step 1100/1642 | Loss: 0.264900 | LR: 0.00000030 | Adv:True
2025-09-22 09:20:52,395 | INFO | Fold 3 | Epoch 3/3 | Step 1200/1642 | Loss: 0.065184 | LR: 0.00000020 | Adv:True
2025-09-22 09:21:27,024 | INFO | Fold 3 | Epoch 3/3 | Step 1300/1642 | Loss: 0.016658 | LR: 0.00000012 | Adv:True
2025-09-22 09:22:01,889 | INFO | Fold 3 | Epoch 3/3 | Step 1400/1642 | Loss: 0.168436 | LR: 0.00000006 | Adv:True
2025-09-22 09:22:36,666 | INFO | Fold 3 | Epoch 3/3 | Step 1500/1642 | Loss: 0.083956 | LR: 0.00000002 | Adv:True
2025-09-22 09:23:11,857 | INFO | Fold 3 | Epoch 3/3 | Step 1600/1642 | Loss: 0.061920 | LR: 0.00000000 | Adv:True
2025-09-22 09:23:26,378 | INFO | Fold 3 | Epoch 3 done. Avg train loss: 0.100411 | Time: 572.77s
2025-09-22 09:23:26,378 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:23:26,384 | INFO | Running validation inference (EMA-applied).
2025-09-22 09:23:34,248 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:23:34,252 | INFO | Fold 3 | Validation epoch 3: MSE(reg)=0.017688, MSE(exp)=0.016840, MSE(blend)=0.017044 | Pearson(reg)=0.868464, Pearson(exp)=0.868307, Pearson(blend)=0.869343
2025-09-22 09:23:34,252 | INFO | Fold 3 | New best validation Pearson (blend): 0.869343 at epoch 3
2025-09-22 09:23:34,252 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:23:34,278 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:23:34,289 | INFO | Fold 3 | Generating OOF predictions with best EMA weights.
2025-09-22 09:23:34,289 | INFO | Running validation inference (EMA-applied).
2025-09-22 09:23:42,173 | INFO | Fold 3 | OOF Pearson (blend): 0.869343
2025-09-22 09:23:42,173 | INFO | Fold 3 | Running test inference.
2025-09-22 09:23:42,173 | INFO | Running test inference (TTA with swapped pairs).
2025-09-22 09:23:50,896 | INFO | ===== Fold 5/5 =====
2025-09-22 09:23:51,238 | INFO | Fold 4 -> Train batches: 1642, Valid batches: 206
2025-09-22 09:23:52,529 | INFO | Creating optimizer parameter groups with layer-wise LR decay.
2025-09-22 09:23:52,531 | INFO | Group 0: params=1, lr=0.00000832, wd=0.01
2025-09-22 09:23:52,531 | INFO | Group 1: params=2, lr=0.00000832, wd=0.0
2025-09-22 09:23:52,531 | INFO | Group 2: params=6, lr=0.00000876, wd=0.01
2025-09-22 09:23:52,531 | INFO | Group 3: params=10, lr=0.00000876, wd=0.0
2025-09-22 09:23:52,531 | INFO | Group 4: params=6, lr=0.00000922, wd=0.01
2025-09-22 09:23:52,531 | INFO | Group 5: params=10, lr=0.00000922, wd=0.0
2025-09-22 09:23:52,532 | INFO | Group 6: params=6, lr=0.00000971, wd=0.01
2025-09-22 09:23:52,532 | INFO | Group 7: params=10, lr=0.00000971, wd=0.0
2025-09-22 09:23:52,533 | INFO | Group 8: params=6, lr=0.00001022, wd=0.01
2025-09-22 09:23:52,533 | INFO | Group 9: params=10, lr=0.00001022, wd=0.0
2025-09-22 09:23:52,533 | INFO | Group 10: params=6, lr=0.00001075, wd=0.01
2025-09-22 09:23:52,533 | INFO | Group 11: params=10, lr=0.00001075, wd=0.0
2025-09-22 09:23:52,533 | INFO | Group 12: params=6, lr=0.00001132, wd=0.01
2025-09-22 09:23:52,533 | INFO | Group 13: params=10, lr=0.00001132, wd=0.0
2025-09-22 09:23:52,533 | INFO | Group 14: params=6, lr=0.00001192, wd=0.01
2025-09-22 09:23:52,533 | INFO | Group 15: params=10, lr=0.00001192, wd=0.0
2025-09-22 09:23:52,533 | INFO | Group 16: params=6, lr=0.00001254, wd=0.01
2025-09-22 09:23:52,533 | INFO | Group 17: params=10, lr=0.00001254, wd=0.0
2025-09-22 09:23:52,533 | INFO | Group 18: params=6, lr=0.00001320, wd=0.01
2025-09-22 09:23:52,533 | INFO | Group 19: params=10, lr=0.00001320, wd=0.0
2025-09-22 09:23:52,533 | INFO | Group 20: params=6, lr=0.00001390, wd=0.01
2025-09-22 09:23:52,533 | INFO | Group 21: params=10, lr=0.00001390, wd=0.0
2025-09-22 09:23:52,533 | INFO | Group 22: params=6, lr=0.00001463, wd=0.01
2025-09-22 09:23:52,533 | INFO | Group 23: params=10, lr=0.00001463, wd=0.0
2025-09-22 09:23:52,533 | INFO | Group 24: params=6, lr=0.00001540, wd=0.01
2025-09-22 09:23:52,533 | INFO | Group 25: params=10, lr=0.00001540, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 26: params=6, lr=0.00001621, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 27: params=10, lr=0.00001621, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 28: params=6, lr=0.00001706, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 29: params=10, lr=0.00001706, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 30: params=6, lr=0.00001796, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 31: params=10, lr=0.00001796, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 32: params=6, lr=0.00001891, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 33: params=10, lr=0.00001891, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 34: params=6, lr=0.00001990, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 35: params=10, lr=0.00001990, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 36: params=6, lr=0.00002095, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 37: params=10, lr=0.00002095, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 38: params=6, lr=0.00002205, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 39: params=10, lr=0.00002205, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 40: params=6, lr=0.00002321, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 41: params=10, lr=0.00002321, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 42: params=6, lr=0.00002444, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 43: params=10, lr=0.00002444, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 44: params=6, lr=0.00002572, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 45: params=10, lr=0.00002572, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 46: params=6, lr=0.00002708, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 47: params=10, lr=0.00002708, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 48: params=6, lr=0.00002850, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 49: params=10, lr=0.00002850, wd=0.0
2025-09-22 09:23:52,534 | INFO | Group 50: params=4, lr=0.00003000, wd=0.01
2025-09-22 09:23:52,534 | INFO | Group 51: params=4, lr=0.00003000, wd=0.0
2025-09-22 09:23:52,536 | INFO | Fold 4 -> Training steps: 4926, Warmup steps: 492, Adv start step: 492
2025-09-22 09:23:52,539 | INFO | Registering EMA shadow parameters.
2025-09-22 09:23:52,545 | INFO | Starting epoch 1/3 for fold 4.
2025-09-22 09:24:17,357 | INFO | Fold 4 | Epoch 1/3 | Step 100/1642 | Loss: 0.615144 | LR: 0.00000169 | Adv:False
2025-09-22 09:24:41,839 | INFO | Fold 4 | Epoch 1/3 | Step 200/1642 | Loss: 0.424720 | LR: 0.00000338 | Adv:False
2025-09-22 09:25:06,568 | INFO | Fold 4 | Epoch 1/3 | Step 300/1642 | Loss: 0.365550 | LR: 0.00000507 | Adv:False
2025-09-22 09:25:31,533 | INFO | Fold 4 | Epoch 1/3 | Step 400/1642 | Loss: 0.307103 | LR: 0.00000677 | Adv:False
2025-09-22 09:25:56,863 | INFO | Fold 4 | Epoch 1/3 | Step 500/1642 | Loss: 0.278467 | LR: 0.00000832 | Adv:True
2025-09-22 09:26:31,455 | INFO | Fold 4 | Epoch 1/3 | Step 600/1642 | Loss: 0.183195 | LR: 0.00000831 | Adv:True
2025-09-22 09:27:05,808 | INFO | Fold 4 | Epoch 1/3 | Step 700/1642 | Loss: 0.287856 | LR: 0.00000828 | Adv:True
2025-09-22 09:27:40,392 | INFO | Fold 4 | Epoch 1/3 | Step 800/1642 | Loss: 0.270631 | LR: 0.00000822 | Adv:True
2025-09-22 09:28:14,866 | INFO | Fold 4 | Epoch 1/3 | Step 900/1642 | Loss: 0.211829 | LR: 0.00000815 | Adv:True
2025-09-22 09:28:49,192 | INFO | Fold 4 | Epoch 1/3 | Step 1000/1642 | Loss: 0.236931 | LR: 0.00000806 | Adv:True
2025-09-22 09:29:23,344 | INFO | Fold 4 | Epoch 1/3 | Step 1100/1642 | Loss: 0.323228 | LR: 0.00000794 | Adv:True
2025-09-22 09:29:57,809 | INFO | Fold 4 | Epoch 1/3 | Step 1200/1642 | Loss: 0.153214 | LR: 0.00000781 | Adv:True
2025-09-22 09:30:31,978 | INFO | Fold 4 | Epoch 1/3 | Step 1300/1642 | Loss: 0.278501 | LR: 0.00000766 | Adv:True
2025-09-22 09:31:06,394 | INFO | Fold 4 | Epoch 1/3 | Step 1400/1642 | Loss: 0.224351 | LR: 0.00000749 | Adv:True
2025-09-22 09:31:41,092 | INFO | Fold 4 | Epoch 1/3 | Step 1500/1642 | Loss: 0.133533 | LR: 0.00000730 | Adv:True
2025-09-22 09:32:15,487 | INFO | Fold 4 | Epoch 1/3 | Step 1600/1642 | Loss: 0.373726 | LR: 0.00000710 | Adv:True
2025-09-22 09:32:29,894 | INFO | Fold 4 | Epoch 1 done. Avg train loss: 0.274822 | Time: 517.35s
2025-09-22 09:32:29,895 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:32:29,901 | INFO | Running validation inference (EMA-applied).
2025-09-22 09:32:38,183 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:32:38,190 | INFO | Fold 4 | Validation epoch 1: MSE(reg)=0.025642, MSE(exp)=0.021725, MSE(blend)=0.021352 | Pearson(reg)=0.842480, Pearson(exp)=0.842190, Pearson(blend)=0.844214
2025-09-22 09:32:38,190 | INFO | Fold 4 | New best validation Pearson (blend): 0.844214 at epoch 1
2025-09-22 09:32:38,191 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:32:38,217 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:32:38,221 | INFO | Starting epoch 2/3 for fold 4.
2025-09-22 09:33:12,074 | INFO | Fold 4 | Epoch 2/3 | Step 100/1642 | Loss: 0.218883 | LR: 0.00000679 | Adv:True
2025-09-22 09:33:45,873 | INFO | Fold 4 | Epoch 2/3 | Step 200/1642 | Loss: 0.233426 | LR: 0.00000656 | Adv:True
2025-09-22 09:34:19,815 | INFO | Fold 4 | Epoch 2/3 | Step 300/1642 | Loss: 0.190492 | LR: 0.00000631 | Adv:True
2025-09-22 09:34:53,519 | INFO | Fold 4 | Epoch 2/3 | Step 400/1642 | Loss: 0.137304 | LR: 0.00000605 | Adv:True
2025-09-22 09:35:27,277 | INFO | Fold 4 | Epoch 2/3 | Step 500/1642 | Loss: 0.123993 | LR: 0.00000579 | Adv:True
2025-09-22 09:36:01,316 | INFO | Fold 4 | Epoch 2/3 | Step 600/1642 | Loss: 0.107245 | LR: 0.00000551 | Adv:True
2025-09-22 09:36:35,064 | INFO | Fold 4 | Epoch 2/3 | Step 700/1642 | Loss: 0.198242 | LR: 0.00000523 | Adv:True
2025-09-22 09:37:08,745 | INFO | Fold 4 | Epoch 2/3 | Step 800/1642 | Loss: 0.187074 | LR: 0.00000494 | Adv:True
2025-09-22 09:37:42,447 | INFO | Fold 4 | Epoch 2/3 | Step 900/1642 | Loss: 0.117897 | LR: 0.00000465 | Adv:True
2025-09-22 09:38:16,313 | INFO | Fold 4 | Epoch 2/3 | Step 1000/1642 | Loss: 0.066243 | LR: 0.00000436 | Adv:True
2025-09-22 09:38:50,009 | INFO | Fold 4 | Epoch 2/3 | Step 1100/1642 | Loss: 0.189329 | LR: 0.00000406 | Adv:True
2025-09-22 09:39:23,890 | INFO | Fold 4 | Epoch 2/3 | Step 1200/1642 | Loss: 0.155994 | LR: 0.00000377 | Adv:True
2025-09-22 09:39:57,701 | INFO | Fold 4 | Epoch 2/3 | Step 1300/1642 | Loss: 0.198145 | LR: 0.00000348 | Adv:True
2025-09-22 09:40:31,929 | INFO | Fold 4 | Epoch 2/3 | Step 1400/1642 | Loss: 0.144470 | LR: 0.00000319 | Adv:True
2025-09-22 09:41:05,851 | INFO | Fold 4 | Epoch 2/3 | Step 1500/1642 | Loss: 0.213567 | LR: 0.00000290 | Adv:True
2025-09-22 09:41:40,245 | INFO | Fold 4 | Epoch 2/3 | Step 1600/1642 | Loss: 0.110067 | LR: 0.00000263 | Adv:True
2025-09-22 09:41:54,650 | INFO | Fold 4 | Epoch 2 done. Avg train loss: 0.161895 | Time: 556.43s
2025-09-22 09:41:54,650 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:41:54,657 | INFO | Running validation inference (EMA-applied).
2025-09-22 09:42:02,520 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:42:02,526 | INFO | Fold 4 | Validation epoch 2: MSE(reg)=0.018586, MSE(exp)=0.016889, MSE(blend)=0.017342 | Pearson(reg)=0.865505, Pearson(exp)=0.865655, Pearson(blend)=0.866451
2025-09-22 09:42:02,526 | INFO | Fold 4 | New best validation Pearson (blend): 0.866451 at epoch 2
2025-09-22 09:42:02,526 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:42:02,554 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:42:02,557 | INFO | Starting epoch 3/3 for fold 4.
2025-09-22 09:42:37,121 | INFO | Fold 4 | Epoch 3/3 | Step 100/1642 | Loss: 0.092884 | LR: 0.00000225 | Adv:True
2025-09-22 09:43:11,408 | INFO | Fold 4 | Epoch 3/3 | Step 200/1642 | Loss: 0.048676 | LR: 0.00000199 | Adv:True
2025-09-22 09:43:45,511 | INFO | Fold 4 | Epoch 3/3 | Step 300/1642 | Loss: 0.108517 | LR: 0.00000174 | Adv:True
2025-09-22 09:44:19,527 | INFO | Fold 4 | Epoch 3/3 | Step 400/1642 | Loss: 0.045880 | LR: 0.00000151 | Adv:True
2025-09-22 09:44:53,718 | INFO | Fold 4 | Epoch 3/3 | Step 500/1642 | Loss: 0.080688 | LR: 0.00000129 | Adv:True
2025-09-22 09:45:27,672 | INFO | Fold 4 | Epoch 3/3 | Step 600/1642 | Loss: 0.049168 | LR: 0.00000108 | Adv:True
2025-09-22 09:46:01,797 | INFO | Fold 4 | Epoch 3/3 | Step 700/1642 | Loss: 0.131728 | LR: 0.00000089 | Adv:True
2025-09-22 09:46:36,126 | INFO | Fold 4 | Epoch 3/3 | Step 800/1642 | Loss: 0.127295 | LR: 0.00000072 | Adv:True
2025-09-22 09:47:10,121 | INFO | Fold 4 | Epoch 3/3 | Step 900/1642 | Loss: 0.134933 | LR: 0.00000056 | Adv:True
2025-09-22 09:47:44,016 | INFO | Fold 4 | Epoch 3/3 | Step 1000/1642 | Loss: 0.069783 | LR: 0.00000042 | Adv:True
2025-09-22 09:48:18,052 | INFO | Fold 4 | Epoch 3/3 | Step 1100/1642 | Loss: 0.066353 | LR: 0.00000030 | Adv:True
2025-09-22 09:48:52,287 | INFO | Fold 4 | Epoch 3/3 | Step 1200/1642 | Loss: 0.121667 | LR: 0.00000020 | Adv:True
2025-09-22 09:49:26,346 | INFO | Fold 4 | Epoch 3/3 | Step 1300/1642 | Loss: 0.086434 | LR: 0.00000012 | Adv:True
2025-09-22 09:50:00,367 | INFO | Fold 4 | Epoch 3/3 | Step 1400/1642 | Loss: 0.099713 | LR: 0.00000006 | Adv:True
2025-09-22 09:50:34,387 | INFO | Fold 4 | Epoch 3/3 | Step 1500/1642 | Loss: 0.054016 | LR: 0.00000002 | Adv:True
2025-09-22 09:51:08,669 | INFO | Fold 4 | Epoch 3/3 | Step 1600/1642 | Loss: 0.165813 | LR: 0.00000000 | Adv:True
2025-09-22 09:51:22,950 | INFO | Fold 4 | Epoch 3 done. Avg train loss: 0.100386 | Time: 560.39s
2025-09-22 09:51:22,950 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:51:22,957 | INFO | Running validation inference (EMA-applied).
2025-09-22 09:51:30,782 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:51:30,788 | INFO | Fold 4 | Validation epoch 3: MSE(reg)=0.018070, MSE(exp)=0.016992, MSE(blend)=0.017299 | Pearson(reg)=0.867134, Pearson(exp)=0.866875, Pearson(blend)=0.867900
2025-09-22 09:51:30,788 | INFO | Fold 4 | New best validation Pearson (blend): 0.867900 at epoch 3
2025-09-22 09:51:30,788 | INFO | Applying EMA weights for evaluation.
2025-09-22 09:51:30,814 | INFO | Restoring original weights after EMA evaluation.
2025-09-22 09:51:30,826 | INFO | Fold 4 | Generating OOF predictions with best EMA weights.
2025-09-22 09:51:30,826 | INFO | Running validation inference (EMA-applied).
2025-09-22 09:51:38,652 | INFO | Fold 4 | OOF Pearson (blend): 0.867900
2025-09-22 09:51:38,652 | INFO | Fold 4 | Running test inference.
2025-09-22 09:51:38,652 | INFO | Running test inference (TTA with swapped pairs).
2025-09-22 09:51:47,364 | INFO | Computing final OOF Pearson.
2025-09-22 09:51:47,366 | INFO | Final OOF Results -> MSE: 0.016867, Pearson: 0.869059
2025-09-22 09:51:47,366 | INFO | Averaging test predictions across folds and preparing submission.
2025-09-22 09:51:47,375 | INFO | Submission saved to: task/us-patent-phrase-to-phrase-matching/outputs/4/submission_5.csv
2025-09-22 09:51:47,375 | INFO | Extra analytics and diagnostics.
2025-09-22 09:51:47,376 | INFO | Train score=0.0: count=6774, pct=20.64%
2025-09-22 09:51:47,376 | INFO | Train score=0.25: count=10306, pct=31.40%
2025-09-22 09:51:47,376 | INFO | Train score=0.5: count=11068, pct=33.72%
2025-09-22 09:51:47,376 | INFO | Train score=0.75: count=3634, pct=11.07%
2025-09-22 09:51:47,376 | INFO | Train score=1.0: count=1043, pct=3.18%
2025-09-22 09:51:47,376 | INFO | Token length diagnostics (first 100 train samples).
2025-09-22 09:51:47,394 | INFO | Token length stats -> mean=50.77, max=77, min=38
2025-09-22 09:51:47,394 | INFO | Pipeline completed with CUDA fp16, 5-fold cross-encoder, MTL head, LLRD, cosine schedule, EMA, FGM, R-Drop, TTA. Submission ready.
