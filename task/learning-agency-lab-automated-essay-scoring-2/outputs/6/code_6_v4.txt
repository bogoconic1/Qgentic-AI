2025-09-21 03:44:08,768 | INFO | Starting AES 2.0 training script (v4) with CUDA and fp16 mixed precision (AMP).
2025-09-21 03:44:08,769 | INFO | Random seeds set to 42.
2025-09-21 03:44:08,769 | INFO | Using device: cuda
2025-09-21 03:44:08,769 | INFO | Data paths set: train=task/learning-agency-lab-automated-essay-scoring-2/train.csv, test=task/learning-agency-lab-automated-essay-scoring-2/test.csv
2025-09-21 03:44:08,770 | INFO | Reading CSVs...
2025-09-21 03:44:09,094 | INFO | Train shape: (15576, 3) | Test shape: (1731, 2)
2025-09-21 03:44:09,095 | INFO | Score distribution (train): {
  "1": 1124,
  "2": 4249,
  "3": 5629,
  "4": 3563,
  "5": 876,
  "6": 135
}
2025-09-21 03:44:09,095 | INFO | Tokenizing and extracting features for train...
2025-09-21 03:44:11,303 | INFO | Processed 2000/15576 train rows
2025-09-21 03:44:13,430 | INFO | Processed 4000/15576 train rows
2025-09-21 03:44:15,600 | INFO | Processed 6000/15576 train rows
2025-09-21 03:44:17,729 | INFO | Processed 8000/15576 train rows
2025-09-21 03:44:19,894 | INFO | Processed 10000/15576 train rows
2025-09-21 03:44:22,064 | INFO | Processed 12000/15576 train rows
2025-09-21 03:44:24,270 | INFO | Processed 14000/15576 train rows
2025-09-21 03:44:25,999 | INFO | Tokenizing and extracting features for test...
2025-09-21 03:44:27,879 | INFO | Feature names (35): ['char_count', 'word_count', 'sentence_count', 'avg_sentence_len', 'paragraph_count', 'comma_count', 'period_count', 'question_count', 'exclam_count', 'quote_count', 'paren_count', 'colon_count', 'semicolon_count', 'dash_count', 'ttr', 'avg_word_len', 'long_word_ratio', 'uppercase_ratio', 'stopword_ratio', 'content_ratio', 'transition_count', 'transitions_per_100w', 'phrase_count', 'phrases_per_100w', 'punctuation_diversity', 'punct_per_word', 'words_per_paragraph', 'sentences_per_paragraph', 'digit_ratio', 'unique_sentence_ratio', 'year_count', 'ly_ratio', 'ion_ratio', 'ing_ratio', 'ed_ratio']
2025-09-21 03:44:28,341 | INFO | Feature means: [2073.4541015625, 373.38385009765625, 19.88629913330078, 20.58951759338379, 4.969247341156006, 12.423151016235352, 19.16884994506836, 0.9051746129989624, 0.26367488503456116, 7.716872215270996, 0.8523369431495667, 0.13251155614852905, 0.1834874153137207, 1.0962377786636353, 0.47494539618492126, 4.3657002449035645, 0.1790665090084076, 0.023597918450832367, 0.47410091757774353, 0.5258996486663818, 33.764957427978516, 9.02308177947998, 0.8407806754112244, 0.22558678686618805, 5.136941432952881, 0.09029829502105713, 91.06897735595703, 4.70564079284668, 0.002770108636468649, 0.9966450929641724, 0.44902414083480835, 0.011106773279607296, 0.010168916545808315, 0.03482295572757721, 0.020398076623678207]
2025-09-21 03:44:28,341 | INFO | Feature stds: [930.0852661132812, 152.76539611816406, 8.829238891601562, 13.583124160766602, 3.3253095149993896, 10.275270462036133, 8.843374252319336, 1.7899751663208008, 1.0468215942382812, 7.364504337310791, 2.515746831893921, 0.6126713156700134, 0.6259998679161072, 2.0394952297210693, 0.07551667094230652, 0.28933778405189514, 0.04934531822800636, 0.023792214691638947, 0.04118097946047783, 0.041180964559316635, 15.712864875793457, 1.9028421640396118, 1.1961551904678345, 0.3192686438560486, 1.9875688552856445, 0.02824396640062332, 56.59357833862305, 2.734421491622925, 0.0037382428999990225, 0.022074930369853973, 1.1104471683502197, 0.0074075497686862946, 0.008169973269104958, 0.015439068898558617, 0.011292178183794022]
2025-09-21 03:44:28,341 | INFO | Hashing tokens to ids for train...
2025-09-21 03:44:29,196 | INFO | Hashed 2000/15576 train token lists
2025-09-21 03:44:30,045 | INFO | Hashed 4000/15576 train token lists
2025-09-21 03:44:30,911 | INFO | Hashed 6000/15576 train token lists
2025-09-21 03:44:31,778 | INFO | Hashed 8000/15576 train token lists
2025-09-21 03:44:32,617 | INFO | Hashed 10000/15576 train token lists
2025-09-21 03:44:33,483 | INFO | Hashed 12000/15576 train token lists
2025-09-21 03:44:34,313 | INFO | Hashed 14000/15576 train token lists
2025-09-21 03:44:34,989 | INFO | Hashing tokens to ids for test...
2025-09-21 03:44:35,729 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=False, token_dropout_p=0.0
2025-09-21 03:44:35,729 | INFO | EssayDataset initialized with 1731 samples.
2025-09-21 03:44:35,734 | INFO | ========== Fold 1/5 ==========
2025-09-21 03:44:35,749 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=True, token_dropout_p=0.04
2025-09-21 03:44:35,749 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=False, token_dropout_p=0.0
2025-09-21 03:44:35,749 | INFO | EssayDataset initialized with 12460 samples.
2025-09-21 03:44:35,749 | INFO | EssayDataset initialized with 3116 samples.
2025-09-21 03:44:36,366 | INFO | Model initialized for fold 1 with 36,405,222 parameters.
2025-09-21 03:44:36,366 | INFO | Model first parameter dtype (should be float32 for AMP): torch.float32
2025-09-21 03:44:37,384 | INFO | Class counts: [899.0, 3399.0, 4503.0, 2851.0, 700.0, 108.0]
2025-09-21 03:44:37,384 | INFO | Computed class weights: [2.309974045235447, 0.6109640090222614, 0.4611740321267303, 0.7283993920261896, 2.966666666666667, 19.228395061728396]
2025-09-21 03:44:37,386 | INFO | LR scheduler initialized: total_steps=2337, warmup_steps=140, base_lr=0.0012
2025-09-21 03:44:37,386 | INFO | Fold 1 | Epoch 1/3 started.
2025-09-21 03:44:42,826 | INFO | Train step 50/779 | Loss: 0.3214 | LR: 0.000429
2025-09-21 03:44:47,364 | INFO | Train step 100/779 | Loss: 0.2430 | LR: 0.000857
2025-09-21 03:44:51,895 | INFO | Train step 150/779 | Loss: 0.2010 | LR: 0.001200
2025-09-21 03:44:56,370 | INFO | Train step 200/779 | Loss: 0.1794 | LR: 0.001198
2025-09-21 03:45:00,883 | INFO | Train step 250/779 | Loss: 0.1696 | LR: 0.001193
2025-09-21 03:45:05,354 | INFO | Train step 300/779 | Loss: 0.1593 | LR: 0.001184
2025-09-21 03:45:09,876 | INFO | Train step 350/779 | Loss: 0.1531 | LR: 0.001173
2025-09-21 03:45:14,348 | INFO | Train step 400/779 | Loss: 0.1483 | LR: 0.001159
2025-09-21 03:45:18,812 | INFO | Train step 450/779 | Loss: 0.1429 | LR: 0.001142
2025-09-21 03:45:23,311 | INFO | Train step 500/779 | Loss: 0.1426 | LR: 0.001122
2025-09-21 03:45:27,778 | INFO | Train step 550/779 | Loss: 0.1376 | LR: 0.001100
2025-09-21 03:45:32,303 | INFO | Train step 600/779 | Loss: 0.1362 | LR: 0.001075
2025-09-21 03:45:36,817 | INFO | Train step 650/779 | Loss: 0.1334 | LR: 0.001047
2025-09-21 03:45:41,323 | INFO | Train step 700/779 | Loss: 0.1334 | LR: 0.001018
2025-09-21 03:45:45,775 | INFO | Train step 750/779 | Loss: 0.1313 | LR: 0.000986
2025-09-21 03:45:48,453 | INFO | Epoch train loss: 0.1305 | Time: 71.07s | Steps: 779
2025-09-21 03:45:51,656 | INFO | Collected validation logits in 3.20s | shape=(3116, 5)
2025-09-21 03:45:51,936 | INFO | Optimized bias on validation: best_bias=0.000, best_QWK=0.728425
2025-09-21 03:45:52,047 | INFO | Fold 1 | Epoch 1 done. TrainLoss=0.1305, ValQWK_raw=0.728425, ValQWK_opt=0.728425, BestQWK_opt=0.728425, BestBias=0.000
2025-09-21 03:45:52,047 | INFO | Fold 1 | Epoch 2/3 started.
2025-09-21 03:45:56,660 | INFO | Train step 50/779 | Loss: 0.0941 | LR: 0.000932
2025-09-21 03:46:01,171 | INFO | Train step 100/779 | Loss: 0.0920 | LR: 0.000895
2025-09-21 03:46:05,633 | INFO | Train step 150/779 | Loss: 0.0958 | LR: 0.000857
2025-09-21 03:46:10,069 | INFO | Train step 200/779 | Loss: 0.0935 | LR: 0.000818
2025-09-21 03:46:14,491 | INFO | Train step 250/779 | Loss: 0.0917 | LR: 0.000777
2025-09-21 03:46:18,943 | INFO | Train step 300/779 | Loss: 0.0955 | LR: 0.000736
2025-09-21 03:46:23,451 | INFO | Train step 350/779 | Loss: 0.0956 | LR: 0.000694
2025-09-21 03:46:27,985 | INFO | Train step 400/779 | Loss: 0.0945 | LR: 0.000651
2025-09-21 03:46:32,502 | INFO | Train step 450/779 | Loss: 0.0938 | LR: 0.000608
2025-09-21 03:46:36,999 | INFO | Train step 500/779 | Loss: 0.0924 | LR: 0.000565
2025-09-21 03:46:41,503 | INFO | Train step 550/779 | Loss: 0.0925 | LR: 0.000523
2025-09-21 03:46:46,063 | INFO | Train step 600/779 | Loss: 0.0918 | LR: 0.000480
2025-09-21 03:46:50,611 | INFO | Train step 650/779 | Loss: 0.0911 | LR: 0.000439
2025-09-21 03:46:55,104 | INFO | Train step 700/779 | Loss: 0.0914 | LR: 0.000398
2025-09-21 03:46:59,568 | INFO | Train step 750/779 | Loss: 0.0906 | LR: 0.000358
2025-09-21 03:47:02,214 | INFO | Epoch train loss: 0.0901 | Time: 70.17s | Steps: 779
2025-09-21 03:47:05,449 | INFO | Collected validation logits in 3.23s | shape=(3116, 5)
2025-09-21 03:47:05,728 | INFO | Optimized bias on validation: best_bias=-0.150, best_QWK=0.733563
2025-09-21 03:47:05,853 | INFO | Fold 1 | Epoch 2 done. TrainLoss=0.0901, ValQWK_raw=0.729450, ValQWK_opt=0.733563, BestQWK_opt=0.733563, BestBias=-0.150
2025-09-21 03:47:05,854 | INFO | Fold 1 | Epoch 3/3 started.
2025-09-21 03:47:10,584 | INFO | Train step 50/779 | Loss: 0.0828 | LR: 0.000298
2025-09-21 03:47:15,068 | INFO | Train step 100/779 | Loss: 0.0806 | LR: 0.000261
2025-09-21 03:47:19,530 | INFO | Train step 150/779 | Loss: 0.0840 | LR: 0.000227
2025-09-21 03:47:24,028 | INFO | Train step 200/779 | Loss: 0.0849 | LR: 0.000194
2025-09-21 03:47:28,565 | INFO | Train step 250/779 | Loss: 0.0845 | LR: 0.000164
2025-09-21 03:47:33,062 | INFO | Train step 300/779 | Loss: 0.0845 | LR: 0.000135
2025-09-21 03:47:37,457 | INFO | Train step 350/779 | Loss: 0.0830 | LR: 0.000109
2025-09-21 03:47:41,906 | INFO | Train step 400/779 | Loss: 0.0823 | LR: 0.000086
2025-09-21 03:47:46,414 | INFO | Train step 450/779 | Loss: 0.0814 | LR: 0.000065
2025-09-21 03:47:50,906 | INFO | Train step 500/779 | Loss: 0.0817 | LR: 0.000047
2025-09-21 03:47:55,364 | INFO | Train step 550/779 | Loss: 0.0818 | LR: 0.000032
2025-09-21 03:47:59,890 | INFO | Train step 600/779 | Loss: 0.0820 | LR: 0.000020
2025-09-21 03:48:04,390 | INFO | Train step 650/779 | Loss: 0.0817 | LR: 0.000010
2025-09-21 03:48:08,872 | INFO | Train step 700/779 | Loss: 0.0808 | LR: 0.000004
2025-09-21 03:48:13,295 | INFO | Train step 750/779 | Loss: 0.0816 | LR: 0.000001
2025-09-21 03:48:15,995 | INFO | Epoch train loss: 0.0813 | Time: 70.14s | Steps: 779
2025-09-21 03:48:19,257 | INFO | Collected validation logits in 3.26s | shape=(3116, 5)
2025-09-21 03:48:19,535 | INFO | Optimized bias on validation: best_bias=0.000, best_QWK=0.738539
2025-09-21 03:48:19,658 | INFO | Fold 1 | Epoch 3 done. TrainLoss=0.0813, ValQWK_raw=0.738539, ValQWK_opt=0.738539, BestQWK_opt=0.738539, BestBias=0.000
2025-09-21 03:48:23,021 | INFO | Collected validation logits in 3.27s | shape=(3116, 5)
2025-09-21 03:48:23,027 | INFO | Fold 1 finished. Best Validation QWK (bias-adjusted): 0.738539 | BestBias=0.000
2025-09-21 03:48:24,919 | INFO | Predicted test logits in 1.89s | shape=(1731, 5)
2025-09-21 03:48:24,943 | INFO | ========== Fold 2/5 ==========
2025-09-21 03:48:24,959 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=True, token_dropout_p=0.04
2025-09-21 03:48:24,959 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=False, token_dropout_p=0.0
2025-09-21 03:48:24,959 | INFO | EssayDataset initialized with 12461 samples.
2025-09-21 03:48:24,966 | INFO | EssayDataset initialized with 3115 samples.
2025-09-21 03:48:25,323 | INFO | Model initialized for fold 2 with 36,405,222 parameters.
2025-09-21 03:48:25,323 | INFO | Model first parameter dtype (should be float32 for AMP): torch.float32
2025-09-21 03:48:25,323 | INFO | Class counts: [899.0, 3399.0, 4503.0, 2851.0, 701.0, 108.0]
2025-09-21 03:48:25,323 | INFO | Computed class weights: [2.3101594364108267, 0.611013043051878, 0.4612110444888593, 0.7284578510464165, 2.962672372800761, 19.229938271604937]
2025-09-21 03:48:25,325 | INFO | LR scheduler initialized: total_steps=2337, warmup_steps=140, base_lr=0.0012
2025-09-21 03:48:25,344 | INFO | Fold 2 | Epoch 1/3 started.
2025-09-21 03:48:29,988 | INFO | Train step 50/779 | Loss: 0.2698 | LR: 0.000429
2025-09-21 03:48:34,524 | INFO | Train step 100/779 | Loss: 0.2160 | LR: 0.000857
2025-09-21 03:48:38,979 | INFO | Train step 150/779 | Loss: 0.1913 | LR: 0.001200
2025-09-21 03:48:43,480 | INFO | Train step 200/779 | Loss: 0.1786 | LR: 0.001198
2025-09-21 03:48:47,995 | INFO | Train step 250/779 | Loss: 0.1650 | LR: 0.001193
2025-09-21 03:48:52,501 | INFO | Train step 300/779 | Loss: 0.1574 | LR: 0.001184
2025-09-21 03:48:57,011 | INFO | Train step 350/779 | Loss: 0.1507 | LR: 0.001173
2025-09-21 03:49:01,519 | INFO | Train step 400/779 | Loss: 0.1450 | LR: 0.001159
2025-09-21 03:49:06,059 | INFO | Train step 450/779 | Loss: 0.1452 | LR: 0.001142
2025-09-21 03:49:10,475 | INFO | Train step 500/779 | Loss: 0.1434 | LR: 0.001122
2025-09-21 03:49:15,004 | INFO | Train step 550/779 | Loss: 0.1398 | LR: 0.001100
2025-09-21 03:49:19,543 | INFO | Train step 600/779 | Loss: 0.1370 | LR: 0.001075
2025-09-21 03:49:24,015 | INFO | Train step 650/779 | Loss: 0.1332 | LR: 0.001047
2025-09-21 03:49:28,503 | INFO | Train step 700/779 | Loss: 0.1308 | LR: 0.001018
2025-09-21 03:49:33,009 | INFO | Train step 750/779 | Loss: 0.1279 | LR: 0.000986
2025-09-21 03:49:35,727 | INFO | Epoch train loss: 0.1268 | Time: 70.38s | Steps: 779
2025-09-21 03:49:38,961 | INFO | Collected validation logits in 3.23s | shape=(3115, 5)
2025-09-21 03:49:39,234 | INFO | Optimized bias on validation: best_bias=0.200, best_QWK=0.703303
2025-09-21 03:49:39,340 | INFO | Fold 2 | Epoch 1 done. TrainLoss=0.1268, ValQWK_raw=0.699904, ValQWK_opt=0.703303, BestQWK_opt=0.703303, BestBias=0.200
2025-09-21 03:49:39,340 | INFO | Fold 2 | Epoch 2/3 started.
2025-09-21 03:49:43,962 | INFO | Train step 50/779 | Loss: 0.0880 | LR: 0.000932
2025-09-21 03:49:48,442 | INFO | Train step 100/779 | Loss: 0.0939 | LR: 0.000895
2025-09-21 03:49:52,887 | INFO | Train step 150/779 | Loss: 0.0915 | LR: 0.000857
2025-09-21 03:49:57,434 | INFO | Train step 200/779 | Loss: 0.1031 | LR: 0.000818
2025-09-21 03:50:01,889 | INFO | Train step 250/779 | Loss: 0.1013 | LR: 0.000777
2025-09-21 03:50:06,451 | INFO | Train step 300/779 | Loss: 0.0999 | LR: 0.000736
2025-09-21 03:50:10,894 | INFO | Train step 350/779 | Loss: 0.0995 | LR: 0.000694
2025-09-21 03:50:15,444 | INFO | Train step 400/779 | Loss: 0.0979 | LR: 0.000651
2025-09-21 03:50:19,985 | INFO | Train step 450/779 | Loss: 0.0979 | LR: 0.000608
2025-09-21 03:50:24,540 | INFO | Train step 500/779 | Loss: 0.0971 | LR: 0.000565
2025-09-21 03:50:29,000 | INFO | Train step 550/779 | Loss: 0.0955 | LR: 0.000523
2025-09-21 03:50:33,473 | INFO | Train step 600/779 | Loss: 0.0948 | LR: 0.000480
2025-09-21 03:50:37,979 | INFO | Train step 650/779 | Loss: 0.0941 | LR: 0.000439
2025-09-21 03:50:42,489 | INFO | Train step 700/779 | Loss: 0.0935 | LR: 0.000398
2025-09-21 03:50:47,040 | INFO | Train step 750/779 | Loss: 0.0925 | LR: 0.000358
2025-09-21 03:50:49,765 | INFO | Epoch train loss: 0.0921 | Time: 70.42s | Steps: 779
2025-09-21 03:50:53,015 | INFO | Collected validation logits in 3.25s | shape=(3115, 5)
2025-09-21 03:50:53,289 | INFO | Optimized bias on validation: best_bias=0.200, best_QWK=0.751841
2025-09-21 03:50:53,413 | INFO | Fold 2 | Epoch 2 done. TrainLoss=0.0921, ValQWK_raw=0.738415, ValQWK_opt=0.751841, BestQWK_opt=0.751841, BestBias=0.200
2025-09-21 03:50:53,413 | INFO | Fold 2 | Epoch 3/3 started.
2025-09-21 03:50:58,085 | INFO | Train step 50/779 | Loss: 0.0750 | LR: 0.000298
2025-09-21 03:51:02,582 | INFO | Train step 100/779 | Loss: 0.0768 | LR: 0.000261
2025-09-21 03:51:07,064 | INFO | Train step 150/779 | Loss: 0.0796 | LR: 0.000227
2025-09-21 03:51:11,455 | INFO | Train step 200/779 | Loss: 0.0781 | LR: 0.000194
2025-09-21 03:51:15,960 | INFO | Train step 250/779 | Loss: 0.0770 | LR: 0.000164
2025-09-21 03:51:20,532 | INFO | Train step 300/779 | Loss: 0.0776 | LR: 0.000135
2025-09-21 03:51:25,021 | INFO | Train step 350/779 | Loss: 0.0767 | LR: 0.000109
2025-09-21 03:51:29,528 | INFO | Train step 400/779 | Loss: 0.0776 | LR: 0.000086
2025-09-21 03:51:34,037 | INFO | Train step 450/779 | Loss: 0.0807 | LR: 0.000065
2025-09-21 03:51:38,570 | INFO | Train step 500/779 | Loss: 0.0804 | LR: 0.000047
2025-09-21 03:51:43,134 | INFO | Train step 550/779 | Loss: 0.0811 | LR: 0.000032
2025-09-21 03:51:47,594 | INFO | Train step 600/779 | Loss: 0.0808 | LR: 0.000020
2025-09-21 03:51:52,124 | INFO | Train step 650/779 | Loss: 0.0801 | LR: 0.000010
2025-09-21 03:51:56,628 | INFO | Train step 700/779 | Loss: 0.0792 | LR: 0.000004
2025-09-21 03:52:01,126 | INFO | Train step 750/779 | Loss: 0.0788 | LR: 0.000001
2025-09-21 03:52:03,857 | INFO | Epoch train loss: 0.0792 | Time: 70.44s | Steps: 779
2025-09-21 03:52:07,124 | INFO | Collected validation logits in 3.27s | shape=(3115, 5)
2025-09-21 03:52:07,400 | INFO | Optimized bias on validation: best_bias=0.000, best_QWK=0.759492
2025-09-21 03:52:07,521 | INFO | Fold 2 | Epoch 3 done. TrainLoss=0.0792, ValQWK_raw=0.759492, ValQWK_opt=0.759492, BestQWK_opt=0.759492, BestBias=0.000
2025-09-21 03:52:10,883 | INFO | Collected validation logits in 3.27s | shape=(3115, 5)
2025-09-21 03:52:10,888 | INFO | Fold 2 finished. Best Validation QWK (bias-adjusted): 0.759492 | BestBias=0.000
2025-09-21 03:52:12,824 | INFO | Predicted test logits in 1.94s | shape=(1731, 5)
2025-09-21 03:52:12,841 | INFO | ========== Fold 3/5 ==========
2025-09-21 03:52:12,857 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=True, token_dropout_p=0.04
2025-09-21 03:52:12,857 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=False, token_dropout_p=0.0
2025-09-21 03:52:12,857 | INFO | EssayDataset initialized with 12461 samples.
2025-09-21 03:52:12,860 | INFO | EssayDataset initialized with 3115 samples.
2025-09-21 03:52:13,524 | INFO | Model initialized for fold 3 with 36,405,222 parameters.
2025-09-21 03:52:13,524 | INFO | Model first parameter dtype (should be float32 for AMP): torch.float32
2025-09-21 03:52:13,524 | INFO | Class counts: [900.0, 3399.0, 4503.0, 2850.0, 701.0, 108.0]
2025-09-21 03:52:13,524 | INFO | Computed class weights: [2.3075925925925924, 0.611013043051878, 0.4612110444888593, 0.7287134502923976, 2.962672372800761, 19.229938271604937]
2025-09-21 03:52:13,526 | INFO | LR scheduler initialized: total_steps=2337, warmup_steps=140, base_lr=0.0012
2025-09-21 03:52:13,546 | INFO | Fold 3 | Epoch 1/3 started.
2025-09-21 03:52:18,162 | INFO | Train step 50/779 | Loss: 0.2918 | LR: 0.000429
2025-09-21 03:52:22,645 | INFO | Train step 100/779 | Loss: 0.2256 | LR: 0.000857
2025-09-21 03:52:27,124 | INFO | Train step 150/779 | Loss: 0.1943 | LR: 0.001200
2025-09-21 03:52:31,683 | INFO | Train step 200/779 | Loss: 0.1784 | LR: 0.001198
2025-09-21 03:52:36,240 | INFO | Train step 250/779 | Loss: 0.1678 | LR: 0.001193
2025-09-21 03:52:40,689 | INFO | Train step 300/779 | Loss: 0.1604 | LR: 0.001184
2025-09-21 03:52:45,153 | INFO | Train step 350/779 | Loss: 0.1529 | LR: 0.001173
2025-09-21 03:52:49,682 | INFO | Train step 400/779 | Loss: 0.1469 | LR: 0.001159
2025-09-21 03:52:54,221 | INFO | Train step 450/779 | Loss: 0.1432 | LR: 0.001142
2025-09-21 03:52:58,752 | INFO | Train step 500/779 | Loss: 0.1390 | LR: 0.001122
2025-09-21 03:53:03,247 | INFO | Train step 550/779 | Loss: 0.1381 | LR: 0.001100
2025-09-21 03:53:07,772 | INFO | Train step 600/779 | Loss: 0.1350 | LR: 0.001075
2025-09-21 03:53:12,290 | INFO | Train step 650/779 | Loss: 0.1325 | LR: 0.001047
2025-09-21 03:53:16,815 | INFO | Train step 700/779 | Loss: 0.1302 | LR: 0.001018
2025-09-21 03:53:21,381 | INFO | Train step 750/779 | Loss: 0.1273 | LR: 0.000986
2025-09-21 03:53:24,095 | INFO | Epoch train loss: 0.1271 | Time: 70.55s | Steps: 779
2025-09-21 03:53:27,343 | INFO | Collected validation logits in 3.25s | shape=(3115, 5)
2025-09-21 03:53:27,621 | INFO | Optimized bias on validation: best_bias=0.400, best_QWK=0.696395
2025-09-21 03:53:27,725 | INFO | Fold 3 | Epoch 1 done. TrainLoss=0.1271, ValQWK_raw=0.631623, ValQWK_opt=0.696395, BestQWK_opt=0.696395, BestBias=0.400
2025-09-21 03:53:27,725 | INFO | Fold 3 | Epoch 2/3 started.
2025-09-21 03:53:32,334 | INFO | Train step 50/779 | Loss: 0.0953 | LR: 0.000932
2025-09-21 03:53:36,823 | INFO | Train step 100/779 | Loss: 0.0919 | LR: 0.000895
2025-09-21 03:53:41,309 | INFO | Train step 150/779 | Loss: 0.0881 | LR: 0.000857
2025-09-21 03:53:45,830 | INFO | Train step 200/779 | Loss: 0.0907 | LR: 0.000818
2025-09-21 03:53:50,352 | INFO | Train step 250/779 | Loss: 0.0905 | LR: 0.000777
2025-09-21 03:53:54,895 | INFO | Train step 300/779 | Loss: 0.0933 | LR: 0.000736
2025-09-21 03:53:59,400 | INFO | Train step 350/779 | Loss: 0.0942 | LR: 0.000694
2025-09-21 03:54:03,851 | INFO | Train step 400/779 | Loss: 0.0933 | LR: 0.000651
2025-09-21 03:54:08,399 | INFO | Train step 450/779 | Loss: 0.0930 | LR: 0.000608
2025-09-21 03:54:12,920 | INFO | Train step 500/779 | Loss: 0.0945 | LR: 0.000565
2025-09-21 03:54:17,431 | INFO | Train step 550/779 | Loss: 0.0928 | LR: 0.000523
2025-09-21 03:54:21,958 | INFO | Train step 600/779 | Loss: 0.0922 | LR: 0.000480
2025-09-21 03:54:26,546 | INFO | Train step 650/779 | Loss: 0.0912 | LR: 0.000439
2025-09-21 03:54:31,106 | INFO | Train step 700/779 | Loss: 0.0918 | LR: 0.000398
2025-09-21 03:54:35,652 | INFO | Train step 750/779 | Loss: 0.0923 | LR: 0.000358
2025-09-21 03:54:38,399 | INFO | Epoch train loss: 0.0919 | Time: 70.67s | Steps: 779
2025-09-21 03:54:41,645 | INFO | Collected validation logits in 3.24s | shape=(3115, 5)
2025-09-21 03:54:41,924 | INFO | Optimized bias on validation: best_bias=-0.150, best_QWK=0.750717
2025-09-21 03:54:42,043 | INFO | Fold 3 | Epoch 2 done. TrainLoss=0.0919, ValQWK_raw=0.747846, ValQWK_opt=0.750717, BestQWK_opt=0.750717, BestBias=-0.150
2025-09-21 03:54:42,043 | INFO | Fold 3 | Epoch 3/3 started.
2025-09-21 03:54:46,732 | INFO | Train step 50/779 | Loss: 0.0698 | LR: 0.000298
2025-09-21 03:54:51,206 | INFO | Train step 100/779 | Loss: 0.0736 | LR: 0.000261
2025-09-21 03:54:55,755 | INFO | Train step 150/779 | Loss: 0.0736 | LR: 0.000227
2025-09-21 03:55:00,222 | INFO | Train step 200/779 | Loss: 0.0739 | LR: 0.000194
2025-09-21 03:55:04,814 | INFO | Train step 250/779 | Loss: 0.0756 | LR: 0.000164
2025-09-21 03:55:09,293 | INFO | Train step 300/779 | Loss: 0.0766 | LR: 0.000135
2025-09-21 03:55:13,749 | INFO | Train step 350/779 | Loss: 0.0758 | LR: 0.000109
2025-09-21 03:55:18,317 | INFO | Train step 400/779 | Loss: 0.0754 | LR: 0.000086
2025-09-21 03:55:22,849 | INFO | Train step 450/779 | Loss: 0.0754 | LR: 0.000065
2025-09-21 03:55:27,370 | INFO | Train step 500/779 | Loss: 0.0752 | LR: 0.000047
2025-09-21 03:55:31,887 | INFO | Train step 550/779 | Loss: 0.0752 | LR: 0.000032
2025-09-21 03:55:36,403 | INFO | Train step 600/779 | Loss: 0.0744 | LR: 0.000020
2025-09-21 03:55:40,948 | INFO | Train step 650/779 | Loss: 0.0741 | LR: 0.000010
2025-09-21 03:55:45,459 | INFO | Train step 700/779 | Loss: 0.0756 | LR: 0.000004
2025-09-21 03:55:49,982 | INFO | Train step 750/779 | Loss: 0.0750 | LR: 0.000001
2025-09-21 03:55:52,719 | INFO | Epoch train loss: 0.0745 | Time: 70.68s | Steps: 779
2025-09-21 03:55:55,971 | INFO | Collected validation logits in 3.25s | shape=(3115, 5)
2025-09-21 03:55:56,248 | INFO | Optimized bias on validation: best_bias=0.000, best_QWK=0.757193
2025-09-21 03:55:56,365 | INFO | Fold 3 | Epoch 3 done. TrainLoss=0.0745, ValQWK_raw=0.757193, ValQWK_opt=0.757193, BestQWK_opt=0.757193, BestBias=0.000
2025-09-21 03:55:59,714 | INFO | Collected validation logits in 3.26s | shape=(3115, 5)
2025-09-21 03:55:59,720 | INFO | Fold 3 finished. Best Validation QWK (bias-adjusted): 0.757193 | BestBias=0.000
2025-09-21 03:56:01,616 | INFO | Predicted test logits in 1.90s | shape=(1731, 5)
2025-09-21 03:56:01,631 | INFO | ========== Fold 4/5 ==========
2025-09-21 03:56:01,646 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=True, token_dropout_p=0.04
2025-09-21 03:56:01,646 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=False, token_dropout_p=0.0
2025-09-21 03:56:01,646 | INFO | EssayDataset initialized with 12461 samples.
2025-09-21 03:56:01,651 | INFO | EssayDataset initialized with 3115 samples.
2025-09-21 03:56:02,066 | INFO | Model initialized for fold 4 with 36,405,222 parameters.
2025-09-21 03:56:02,066 | INFO | Model first parameter dtype (should be float32 for AMP): torch.float32
2025-09-21 03:56:02,066 | INFO | Class counts: [899.0, 3400.0, 4503.0, 2850.0, 701.0, 108.0]
2025-09-21 03:56:02,066 | INFO | Computed class weights: [2.3101594364108267, 0.6108333333333333, 0.4612110444888593, 0.7287134502923976, 2.962672372800761, 19.229938271604937]
2025-09-21 03:56:02,068 | INFO | LR scheduler initialized: total_steps=2337, warmup_steps=140, base_lr=0.0012
2025-09-21 03:56:02,088 | INFO | Fold 4 | Epoch 1/3 started.
2025-09-21 03:56:06,732 | INFO | Train step 50/779 | Loss: 0.2755 | LR: 0.000429
2025-09-21 03:56:11,241 | INFO | Train step 100/779 | Loss: 0.2260 | LR: 0.000857
2025-09-21 03:56:15,805 | INFO | Train step 150/779 | Loss: 0.1879 | LR: 0.001200
2025-09-21 03:56:20,351 | INFO | Train step 200/779 | Loss: 0.1778 | LR: 0.001198
2025-09-21 03:56:24,844 | INFO | Train step 250/779 | Loss: 0.1636 | LR: 0.001193
2025-09-21 03:56:29,372 | INFO | Train step 300/779 | Loss: 0.1580 | LR: 0.001184
2025-09-21 03:56:33,904 | INFO | Train step 350/779 | Loss: 0.1540 | LR: 0.001173
2025-09-21 03:56:38,420 | INFO | Train step 400/779 | Loss: 0.1467 | LR: 0.001159
2025-09-21 03:56:42,897 | INFO | Train step 450/779 | Loss: 0.1440 | LR: 0.001142
2025-09-21 03:56:47,368 | INFO | Train step 500/779 | Loss: 0.1380 | LR: 0.001122
2025-09-21 03:56:52,000 | INFO | Train step 550/779 | Loss: 0.1348 | LR: 0.001100
2025-09-21 03:56:56,473 | INFO | Train step 600/779 | Loss: 0.1325 | LR: 0.001075
2025-09-21 03:57:00,926 | INFO | Train step 650/779 | Loss: 0.1291 | LR: 0.001047
2025-09-21 03:57:05,382 | INFO | Train step 700/779 | Loss: 0.1268 | LR: 0.001018
2025-09-21 03:57:09,919 | INFO | Train step 750/779 | Loss: 0.1250 | LR: 0.000986
2025-09-21 03:57:12,680 | INFO | Epoch train loss: 0.1245 | Time: 70.59s | Steps: 779
2025-09-21 03:57:15,930 | INFO | Collected validation logits in 3.25s | shape=(3115, 5)
2025-09-21 03:57:16,210 | INFO | Optimized bias on validation: best_bias=-0.050, best_QWK=0.718024
2025-09-21 03:57:16,314 | INFO | Fold 4 | Epoch 1 done. TrainLoss=0.1245, ValQWK_raw=0.716379, ValQWK_opt=0.718024, BestQWK_opt=0.718024, BestBias=-0.050
2025-09-21 03:57:16,314 | INFO | Fold 4 | Epoch 2/3 started.
2025-09-21 03:57:21,020 | INFO | Train step 50/779 | Loss: 0.1411 | LR: 0.000932
2025-09-21 03:57:25,516 | INFO | Train step 100/779 | Loss: 0.1222 | LR: 0.000895
2025-09-21 03:57:30,051 | INFO | Train step 150/779 | Loss: 0.1049 | LR: 0.000857
2025-09-21 03:57:34,560 | INFO | Train step 200/779 | Loss: 0.1036 | LR: 0.000818
2025-09-21 03:57:39,104 | INFO | Train step 250/779 | Loss: 0.1026 | LR: 0.000777
2025-09-21 03:57:43,537 | INFO | Train step 300/779 | Loss: 0.0994 | LR: 0.000736
2025-09-21 03:57:48,090 | INFO | Train step 350/779 | Loss: 0.0982 | LR: 0.000694
2025-09-21 03:57:52,589 | INFO | Train step 400/779 | Loss: 0.0971 | LR: 0.000651
2025-09-21 03:57:57,121 | INFO | Train step 450/779 | Loss: 0.0964 | LR: 0.000608
2025-09-21 03:58:01,597 | INFO | Train step 500/779 | Loss: 0.0957 | LR: 0.000565
2025-09-21 03:58:06,094 | INFO | Train step 550/779 | Loss: 0.0951 | LR: 0.000523
2025-09-21 03:58:10,631 | INFO | Train step 600/779 | Loss: 0.0949 | LR: 0.000480
2025-09-21 03:58:15,186 | INFO | Train step 650/779 | Loss: 0.0950 | LR: 0.000439
2025-09-21 03:58:19,716 | INFO | Train step 700/779 | Loss: 0.0947 | LR: 0.000398
2025-09-21 03:58:24,194 | INFO | Train step 750/779 | Loss: 0.0940 | LR: 0.000358
2025-09-21 03:58:26,950 | INFO | Epoch train loss: 0.0938 | Time: 70.64s | Steps: 779
2025-09-21 03:58:30,227 | INFO | Collected validation logits in 3.28s | shape=(3115, 5)
2025-09-21 03:58:30,508 | INFO | Optimized bias on validation: best_bias=0.000, best_QWK=0.759187
2025-09-21 03:58:30,627 | INFO | Fold 4 | Epoch 2 done. TrainLoss=0.0938, ValQWK_raw=0.759187, ValQWK_opt=0.759187, BestQWK_opt=0.759187, BestBias=0.000
2025-09-21 03:58:30,627 | INFO | Fold 4 | Epoch 3/3 started.
2025-09-21 03:58:35,335 | INFO | Train step 50/779 | Loss: 0.0885 | LR: 0.000298
2025-09-21 03:58:39,834 | INFO | Train step 100/779 | Loss: 0.0825 | LR: 0.000261
2025-09-21 03:58:44,421 | INFO | Train step 150/779 | Loss: 0.0803 | LR: 0.000227
2025-09-21 03:58:48,857 | INFO | Train step 200/779 | Loss: 0.0801 | LR: 0.000194
2025-09-21 03:58:53,367 | INFO | Train step 250/779 | Loss: 0.0792 | LR: 0.000164
2025-09-21 03:58:57,908 | INFO | Train step 300/779 | Loss: 0.0799 | LR: 0.000135
2025-09-21 03:59:02,407 | INFO | Train step 350/779 | Loss: 0.0809 | LR: 0.000109
2025-09-21 03:59:06,925 | INFO | Train step 400/779 | Loss: 0.0799 | LR: 0.000086
2025-09-21 03:59:11,426 | INFO | Train step 450/779 | Loss: 0.0789 | LR: 0.000065
2025-09-21 03:59:15,986 | INFO | Train step 500/779 | Loss: 0.0791 | LR: 0.000047
2025-09-21 03:59:20,505 | INFO | Train step 550/779 | Loss: 0.0788 | LR: 0.000032
2025-09-21 03:59:24,984 | INFO | Train step 600/779 | Loss: 0.0781 | LR: 0.000020
2025-09-21 03:59:29,492 | INFO | Train step 650/779 | Loss: 0.0792 | LR: 0.000010
2025-09-21 03:59:34,000 | INFO | Train step 700/779 | Loss: 0.0790 | LR: 0.000004
2025-09-21 03:59:38,528 | INFO | Train step 750/779 | Loss: 0.0781 | LR: 0.000001
2025-09-21 03:59:41,256 | INFO | Epoch train loss: 0.0782 | Time: 70.63s | Steps: 779
2025-09-21 03:59:44,548 | INFO | Collected validation logits in 3.29s | shape=(3115, 5)
2025-09-21 03:59:44,829 | INFO | Optimized bias on validation: best_bias=0.100, best_QWK=0.765357
2025-09-21 03:59:44,950 | INFO | Fold 4 | Epoch 3 done. TrainLoss=0.0782, ValQWK_raw=0.764675, ValQWK_opt=0.765357, BestQWK_opt=0.765357, BestBias=0.100
2025-09-21 03:59:48,348 | INFO | Collected validation logits in 3.31s | shape=(3115, 5)
2025-09-21 03:59:48,354 | INFO | Fold 4 finished. Best Validation QWK (bias-adjusted): 0.765357 | BestBias=0.100
2025-09-21 03:59:50,269 | INFO | Predicted test logits in 1.91s | shape=(1731, 5)
2025-09-21 03:59:50,289 | INFO | ========== Fold 5/5 ==========
2025-09-21 03:59:50,305 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=True, token_dropout_p=0.04
2025-09-21 03:59:50,305 | INFO | CollatorSegments created | max_len=512, payload_len=511, stride=447, num_features=35, cls_id=1, training=False, token_dropout_p=0.0
2025-09-21 03:59:50,305 | INFO | EssayDataset initialized with 12461 samples.
2025-09-21 03:59:50,308 | INFO | EssayDataset initialized with 3115 samples.
2025-09-21 03:59:50,661 | INFO | Model initialized for fold 5 with 36,405,222 parameters.
2025-09-21 03:59:50,661 | INFO | Model first parameter dtype (should be float32 for AMP): torch.float32
2025-09-21 03:59:50,661 | INFO | Class counts: [899.0, 3399.0, 4504.0, 2850.0, 701.0, 108.0]
2025-09-21 03:59:50,661 | INFO | Computed class weights: [2.3101594364108267, 0.611013043051878, 0.46110864416814684, 0.7287134502923976, 2.962672372800761, 19.229938271604937]
2025-09-21 03:59:50,663 | INFO | LR scheduler initialized: total_steps=2337, warmup_steps=140, base_lr=0.0012
2025-09-21 03:59:50,682 | INFO | Fold 5 | Epoch 1/3 started.
