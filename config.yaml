llm:
  developer_model: "gpt-5"
  developer_tool_model: "gpt-5"
  researcher_model: "gpt-5"
  researcher_tool_offline_model: "gpt-5"
  researcher_tool_online_model: "gpt-5"
  model_selector_model: "gpt-5"
  model_recommender_model: "gemini-2.5-pro"
  starter_model: "gpt-5"
  ensembler_model: "gpt-5"
  finetuned_code_api_model: "projects/134356426507/locations/us-central1/endpoints/7532524363963170816"
runtime:
  ask_eda_max_attempts: 5
  download_datasets_max_attempts: 1
  researcher_max_steps: 512
  llm_max_retries: 3
  directory_listing_max_files: 10
  researcher_parallel_runs: 1
  patch_mode_enabled: false
  # Parallel baseline execution
  baseline_max_parallel_workers: 3  # Max baselines running in parallel when GPU isolation is disabled (ignored if enable_mig or enable_multi_gpu is true)
  # GPU isolation strategy (choose ONE or neither):
  enable_mig: false  # Use NVIDIA MIG for single-GPU partitioning (auto-detects number of workers from MIG instances)
  enable_multi_gpu: true  # Use multi-GPU setup (auto-detects number of workers from available GPUs)
  allowed_gpu_ids: []  # Optional: Restrict to specific GPU IDs. If empty or null, uses all detected GPUs.
  enable_cpu_affinity: true  # Pin processes to specific CPU cores
  # Conda environment isolation
  reset_conda_envs_per_run: true # If true, delete and recreate conda environments on each run for clean slate (slower startup). If false, reuse existing environments (faster but accumulates packages over time)
  # Time limits (in seconds)
  baseline_time_limit: 10800  # 3 hours for baseline development
  ensemble_time_limit: 14400  # 4 hours for ensemble phase
  baseline_code_timeout: 5400  # 1.5 hours for baseline code execution
  ensemble_code_timeout: 10800  # 3 hours for ensemble code execution
paths:
  task_root: "task"
  outputs_dirname: "outputs"
  external_data_dirname: "external-data"
guardrails:
  logging_basicconfig_order: true
tracking:
  wandb:
    entity: 520f8592abc # replace with your W&B entity
    project: qgentic-ai # replace with your W&B project
model_recommender:
  default_models: ["deberta-v3-large"]  # List of models to recommend strategies for
  enable_web_search: true  # Enable web search for finding SOTA strategies
