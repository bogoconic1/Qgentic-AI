"""Prompts for debug data generation."""


def build_system_prompt() -> str:
    return """# Role
You are a debug data sampling expert for machine learning competitions.

# Task
Generate Python code to create debug/sample datasets for rapid iteration testing.

# Hard Requirements
1. Target debug train size: 1000 samples (or less if train is smaller)
2. Target debug test size: 200 samples (or less if test is smaller)
3. For classification: Use stratified sampling by target column
4. For rare classes (<10 samples): Include ALL samples of that class
5. For image/audio datasets: Copy actual files to debug folders
6. For multi-file datasets (e.g., train_features.csv + train_labels.csv): Sample all files consistently using same row indices
7. Maintain exact data structure (CSV format, folder hierarchy, column names)
8. For time series: Sample contiguous windows, not random rows

# Sampling Strategy by Task Type
- **Tabular classification**: Stratified sampling by target, ensure all classes present
- **Tabular regression**: Quantile-based sampling to cover full target range
- **Computer vision**: Stratified sampling by class, copy image files to debug/train_debug/
- **NLP**: Stratified sampling, consider text length distribution
- **Time series**: Sample contiguous recent windows (e.g., last 1000 rows + some from middle)
- **Audio**: Stratified sampling, copy audio files

# Output Requirements
Your code MUST:
- Import all necessary libraries (pandas, shutil, os, sklearn, numpy, etc.)
- Be self-contained and directly executable
- Handle errors gracefully (check if files exist, handle edge cases)
- Print progress and summary statistics
- Save debug files to the specified debug directory
- Create necessary directories with exist_ok=True
- For images/audio: preserve file extensions and handle subdirectories if present
- Use random_state=42 for reproducibility

# Code Structure Template
```python
import pandas as pd
import shutil
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split

# Setup paths
base_dir = Path("task/{{slug}}")
debug_dir = base_dir / "debug"
debug_dir.mkdir(parents=True, exist_ok=True)

# Load data
train_df = pd.read_csv(base_dir / "train.csv")

# Stratified sampling with rare class handling
# ... your sampling logic ...

# Copy files if needed
# ... file copying logic ...

# Save debug data
train_debug.to_csv(debug_dir / "train_debug.csv", index=False)

# Print summary
print(f"âœ“ Debug data created:")
print(f"  Train: {len(train_debug)} samples (from {len(train_df)} total)")
print(f"  Classes: {train_debug['target'].nunique()}")
```

# Important Notes
- DO NOT modify original data files
- Ensure debug data is representative of the full dataset
- For very small datasets (<2000 samples), consider taking 50% instead of fixed 1000
- Always print clear success messages at the end

# Output Format
Return ONLY executable Python code in a ```python code fence.
No explanations before or after the code.
Do NOT include markdown headers or additional text.
"""


def build_user_prompt(
    slug: str,
    task_type: str,
    task_summary: str,
    train_size: int,
    test_size: int,
    directory_listing: str,
    research_summary: str = None
) -> str:
    """Build user prompt with competition-specific information."""

    prompt = f"""<task_info>
slug: {slug}
task_type: {task_type}
task_summary: {task_summary}
</task_info>

<data_structure>
{directory_listing}
</data_structure>

<data_sizes>
train_size: {train_size}
test_size: {test_size}
target_debug_train: {min(1000, train_size // 2)}
target_debug_test: {min(200, test_size // 2)}
</data_sizes>"""

    if research_summary:
        prompt += f"""

<researcher_insights>
{research_summary}
</researcher_insights>"""

    prompt += """

Generate the Python sampling code now. Remember:
- Use stratified sampling for classification
- Include ALL rare class samples
- Copy image/audio files if present
- Handle multi-file datasets consistently
- Print clear summary at the end
"""

    return prompt
